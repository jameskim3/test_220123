{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:36:40.103136Z",
     "start_time": "2020-06-03T12:36:40.094134Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_rows = 150\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "batch_size=48\n",
    "epochs=300\n",
    "subject='Severstal'\n",
    "main_path=os.path.join(\"E:\\\\kaggle_imgs\",subject)\n",
    "img_path=os.path.join(main_path,\"images\")\n",
    "data_path=os.path.join(main_path,\"Data\")\n",
    "saved_path=os.path.join(main_path,\"saved_models\")\n",
    "paths=[main_path, img_path,saved_path,data_path]\n",
    "for fp in paths:\n",
    "        print(fp)\n",
    "        if not os.path.exists(fp):        \n",
    "                os.mkdir(fp)\n",
    "file_path=os.path.join(saved_path,subject+\"200608_\")\n",
    "file_best=os.path.join(saved_path,subject+\"200608_\")\n",
    "\n",
    "train_img_pkl=os.path.join(data_path,\"train_imgs.npy\")\n",
    "test_img_pkl=os.path.join(data_path,\"test_imgs.npy\")\n",
    "train_info_pkl=os.path.join(data_path,\"df_train_pickle.csv\")\n",
    "\n",
    "num_classes=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "def get_train_info():\n",
    "        df=pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
    "        files = os.listdir(os.path.join(data_path, \"train_images\"))\n",
    "        df_all_images=pd.DataFrame({\"ImageId\":files})\n",
    "        df_NoDefect=df_all_images[~df_all_images.ImageId.isin(df.ImageId)]\n",
    "        df_NoDefect[\"ClassId\"]=0\n",
    "        df_NoDefect[\"EncodedPixels\"]=np.NaN\n",
    "        df_train=pd.concat([df,df_NoDefect]).reset_index(drop=True)    \n",
    "    \n",
    "        legacy_df=pd.DataFrame(columns=[\"ImageId_ClassId\",\"EncodedPixels\"])\n",
    "        my_group=df_train.groupby(\"ImageId\")\n",
    "        for img_id,img_df in tqdm_notebook(my_group):\n",
    "                for i in range(1,5):\n",
    "                        avail_classes = list(img_df.ClassId)\n",
    "                        row = dict()\n",
    "                        row['ImageId_ClassId'] = img_id + '_' + str(i)\n",
    "\n",
    "                        if i in avail_classes:\n",
    "                                row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n",
    "                        else:\n",
    "                                row['EncodedPixels'] = np.nan\n",
    "\n",
    "                        legacy_df = legacy_df.append(row, ignore_index=True)\n",
    "        return legacy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=train_info_pkl\n",
    "if os.path.exists(fp):\n",
    "    df_train=pd.read_csv(fp)\n",
    "    print(\"df_train load complete\")\n",
    "else:\n",
    "    df_train=get_train_info()\n",
    "    df_train['ImageId'] = df_train['ImageId_ClassId'].map(lambda x: x.split('_')[0])\n",
    "    df_train['ClassId'] = df_train['ImageId_ClassId'].map(lambda x: x.split('_')[1])\n",
    "    df_train['HavingDefection'] = df_train['EncodedPixels'].map(lambda x: 0 if x is np.nan else 1)\n",
    "    df_train.to_csv(fp,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_and_mask(start_idx):\n",
    "    col = start_idx\n",
    "    img_names = [str(i).split(\"_\")[0] for i in df_train.iloc[col:col+4, 0].values]\n",
    "#     if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n",
    "#         raise ValueError\n",
    "\n",
    "    labels = df_train.iloc[col:col+4, 1]\n",
    "    mask = np.zeros((256, 1600, 4), dtype=np.uint8)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            mask_label = np.zeros(1600*256, dtype=np.uint8)\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask_label[pos-1:pos+le-1] = 1\n",
    "            mask[:, :, idx] = mask_label.reshape(256, 1600, order='F')\n",
    "    return img_names[0], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask_image(col):\n",
    "    name, mask = name_and_mask(col)\n",
    "    img = cv2.imread(os.path.join(data_path, f\"train_images/{name}\"))\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for ch in range(4):\n",
    "        _,contours,_ = cv2.findContours(mask[:, :, ch].astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        for i in range(0, len(contours)):\n",
    "            cv2.polylines(img, contours[i], True, palet[ch], 2)\n",
    "    ax.set_title(name)\n",
    "    ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    if df_train.iloc[i,2]==1:\n",
    "                     show_mask_image(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to simplify , n this kernel i use only images with classid 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=df_train.copy()\n",
    "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
    "df_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\n",
    "print(len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decode mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(rle, imgshape):\n",
    "    width = imgshape[0]\n",
    "    height= imgshape[1]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MY Test\"\"\"\n",
    "img = cv2.imread( data_path + '/train_images/000f6bf48.jpg' )\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n",
    "img[mask==1,0] = 64\n",
    "plt.imshow(mask)\n",
    "print(\"mask\",mask.sum(),mask.shape)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 1\n",
    "rows = 4\n",
    "\n",
    "for i in range(30):\n",
    "    if df_train.iloc[i,2]==0:\n",
    "        continue\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    fn = df_train.iloc[i,3]\n",
    "    #fig.add_subplot(rows, columns, i).set_title(fn)\n",
    "    img = cv2.imread( data_path + '/train_images/'+fn )\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n",
    "    img[mask==1,0] = 255\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train Dataset ans DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import (Normalize, Compose)\n",
    "from albumentations.torch import ToTensor\n",
    "from torchvision import transforms\n",
    "\n",
    "class ImageData(Dataset):\n",
    "    def __init__(self, df, transform, subset=\"train\"):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.subset = subset\n",
    "        \n",
    "        if self.subset == \"train\":\n",
    "            self.data_path = data_path + '/train_images/'\n",
    "        elif self.subset == \"test\":\n",
    "            self.data_path = data_path + '/test_images/'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):                      \n",
    "        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n",
    "        img = Image.open(self.data_path + fn)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        if self.subset == 'train': \n",
    "            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n",
    "            mask = transforms.ToPILImage()(mask)            \n",
    "            mask = self.transform(mask)\n",
    "            return img, mask\n",
    "        else: \n",
    "            mask = None\n",
    "            return img   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transf = transforms.Compose([\n",
    "                                  transforms.Scale((256, 256)),\n",
    "                                  transforms.ToTensor()])\n",
    "train_data = ImageData(df = df_train, transform = data_transf)\n",
    "train_loader = DataLoader(dataset = train_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,mask in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[1].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[5][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(train_data[5][1].permute(1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18()\n",
    "        #self.base_model.load_state_dict(torch.load(\"../input/resnet18/resnet18.pth\"))\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3])\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer2 = self.base_layers[5]\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "        self.layer3 = self.base_layers[6]\n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "        self.layer4 = self.base_layers[7]\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=UNet(n_class=1).cuda()\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),weight_decay=1e-4,lr=0.001,momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "        data,target=data.cuda(),target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {epoch}, Loss {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show prediction on image from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[6][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[6][0].unsqueeze(0)\n",
    "o = model(x.cuda())  \n",
    "o = o.cpu().detach().numpy() * (-1)\n",
    "tmp = np.copy(o)\n",
    "mn = np.mean(o)*1.2\n",
    "tmp[tmp<mn] = 0\n",
    "tmp[tmp>mn] = 1\n",
    "plt.imshow(np.squeeze(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=pd.read_csv(data_path+\"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=ImageData(df=sub4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
