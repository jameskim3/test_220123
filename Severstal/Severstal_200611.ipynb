{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:36:40.103136Z",
     "start_time": "2020-06-03T12:36:40.094134Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_rows = 150\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "batch_size=48\n",
    "epochs=300\n",
    "subject='Severstal'\n",
    "main_path=os.path.join(\"E:\\\\kaggle_imgs\",subject)\n",
    "img_path=os.path.join(main_path,\"images\")\n",
    "data_path=os.path.join(main_path,\"Data\")\n",
    "saved_path=os.path.join(main_path,\"saved_models\")\n",
    "paths=[main_path, img_path,saved_path,data_path]\n",
    "for fp in paths:\n",
    "        print(fp)\n",
    "        if not os.path.exists(fp):        \n",
    "                os.mkdir(fp)\n",
    "file_path=os.path.join(saved_path,subject+\"200608_\")\n",
    "file_best=os.path.join(saved_path,subject+\"200608_\")\n",
    "\n",
    "train_img_pkl=os.path.join(data_path,\"train_imgs.npy\")\n",
    "test_img_pkl=os.path.join(data_path,\"test_imgs.npy\")\n",
    "train_info_pkl=os.path.join(data_path,\"df_train_pickle.csv\")\n",
    "\n",
    "num_classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in paths:\n",
    "        print (fp)\n",
    "        if 0:\n",
    "for fp in\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "def get_train_info():\n",
    "        df=pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
    "        files = os.listdir(os.path.join(data_path, \"train_images\"))\n",
    "        df_all_images=pd.DataFrame({\"ImageId\":files})\n",
    "        df_NoDefect=df_all_images[~df_all_images.ImageId.isin(df.ImageId)]\n",
    "        df_NoDefect[\"ClassId\"]=0\n",
    "        df_NoDefect[\"EncodedPixels\"]=np.NaN\n",
    "        df_train=pd.concat([df,df_NoDefect]).reset_index(drop=True)    \n",
    "    \n",
    "        legacy_df=pd.DataFrame(columns=[\"ImageId_ClassId\",\"EncodedPixels\"])\n",
    "        my_group=df_train.groupby(\"ImageId\")\n",
    "        for img_id,img_df in tqdm_notebook(my_group):\n",
    "                for i in range(1,5):\n",
    "                        avail_classes = list(img_df.ClassId)\n",
    "\n",
    "        row = dict()\n",
    "        row['ImageId_ClassId'] = img_id + '_' + str(i)\n",
    "\n",
    "        if i in avail_classes:\n",
    "                row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n",
    "        else:\n",
    "                row['EncodedPixels'] = np.nan\n",
    "\n",
    "        legacy_df = legacy_df.append(row, ignore_index=True)\n",
    "        return legacy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=train_info_pkl\n",
    "if os.path.exists(fp):\n",
    "    df_train=pd.read_csv(fp)\n",
    "    print(\"df_train load complete\")\n",
    "else:\n",
    "    df_train=get_train_info()\n",
    "    df_train['Image'] = df_train['ImageId_ClassId'].map(lambda x: x.split('_')[0])\n",
    "    df_train['HavingDefection'] = df_train['EncodedPixels'].map(lambda x: 0 if x is np.nan else 1)\n",
    "    df_train.to_csv(fp,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_col = np.array(df_train['Image'])\n",
    "image_files = image_col[::4]\n",
    "all_labels = np.array(df_train['HavingDefection']).reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, check the number of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = defaultdict(int)\n",
    "\n",
    "kind_class_dict = defaultdict(int)\n",
    "\n",
    "no_defects_num = 0\n",
    "defects_num = 0\n",
    "\n",
    "for col in range(0, len(df_train), 4):\n",
    "    img_names = [str(i).split(\"_\")[0] for i in df_train.iloc[col:col+4, 0].values]\n",
    "    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n",
    "        raise ValueError\n",
    "        \n",
    "    labels = df_train.iloc[col:col+4, 1]\n",
    "    if labels.isna().all():\n",
    "        no_defects_num += 1\n",
    "    else:\n",
    "        defects_num += 1\n",
    "    \n",
    "    kind_class_dict[sum(labels.isna().values == False)] += 1\n",
    "        \n",
    "    for idx, label in enumerate(labels.isna().values.tolist()):\n",
    "        if label == False:\n",
    "            class_dict[idx+1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the number of images with no defects: {}\".format(no_defects_num))\n",
    "print(\"the number of images with defects: {}\".format(defects_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(class_dict.keys()), y=list(class_dict.values()), ax=ax)\n",
    "ax.set_title(\"the number of images for each class\")\n",
    "ax.set_xlabel(\"class\")\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(kind_class_dict.keys()), y=list(kind_class_dict.values()), ax=ax)\n",
    "ax.set_title(\"Number of classes included in each image\");\n",
    "ax.set_xlabel(\"number of classes in the image\")\n",
    "kind_class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "train_size_dict = defaultdict(int)\n",
    "train_path = Path(data_path, \"train_images/\")\n",
    "\n",
    "for img_name in train_path.iterdir():\n",
    "    img = Image.open(img_name)\n",
    "    train_size_dict[img.size] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_dict = defaultdict(int)\n",
    "test_path = Path(data_path,\"test_images/\")\n",
    "\n",
    "for img_name in test_path.iterdir():\n",
    "    img = Image.open(img_name)\n",
    "    test_size_dict[img.size] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualization mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_and_mask(start_idx):\n",
    "    col = start_idx\n",
    "    img_names = [str(i).split(\"_\")[0] for i in df_train.iloc[col:col+4, 0].values]\n",
    "    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n",
    "        raise ValueError\n",
    "\n",
    "    labels = df_train.iloc[col:col+4, 1]\n",
    "    mask = np.zeros((256, 1600, 4), dtype=np.uint8)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            mask_label = np.zeros(1600*256, dtype=np.uint8)\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask_label[pos-1:pos+le-1] = 1\n",
    "            mask[:, :, idx] = mask_label.reshape(256, 1600, order='F')\n",
    "    return img_names[0], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask_image(col):\n",
    "    name, mask = name_and_mask(col)\n",
    "    img = cv2.imread(str(train_path / name))\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for ch in range(4):\n",
    "        #contours, _ = cv2.findContours(mask[:, :, ch], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        _,contours,_ = cv2.findContours(mask[:, :, ch].astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        for i in range(0, len(contours)):\n",
    "            cv2.polylines(img, contours[i], True, palet[ch], 2)\n",
    "    ax.set_title(name)\n",
    "    ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "for i in range(4):\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(np.ones((50, 50, 3), dtype=np.uint8) * palet[i])\n",
    "    ax[i].set_title(\"class color: {}\".format(i+1))\n",
    "fig.suptitle(\"each class colors\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images with no defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_no_defect = []\n",
    "idx_class_1 = []\n",
    "idx_class_2 = []\n",
    "idx_class_3 = []\n",
    "idx_class_4 = []\n",
    "idx_class_multi = []\n",
    "idx_class_triple = []\n",
    "\n",
    "for col in range(0, len(df_train), 4):\n",
    "    img_names = [str(i).split(\"_\")[0] for i in df_train.iloc[col:col+4, 0].values]\n",
    "    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n",
    "        raise ValueError\n",
    "        \n",
    "    labels = df_train.iloc[col:col+4, 1]\n",
    "    if labels.isna().all():\n",
    "        idx_no_defect.append(col)\n",
    "    elif (labels.isna() == [False, True, True, True]).all():\n",
    "        idx_class_1.append(col)\n",
    "    elif (labels.isna() == [True, False, True, True]).all():\n",
    "        idx_class_2.append(col)\n",
    "    elif (labels.isna() == [True, True, False, True]).all():\n",
    "        idx_class_3.append(col)\n",
    "    elif (labels.isna() == [True, True, True, False]a).all():\n",
    "        idx_class_4.append(col)\n",
    "    elif labels.isna().sum() == 1:\n",
    "        idx_class_triple.append(col)\n",
    "    else:\n",
    "        idx_class_multi.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_no_defect[:5]:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_class_1[:5]:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_class_2[:5]:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_class_3[:5]:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_class_4[:5]:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_class_multi[:5]:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_class_triple:\n",
    "    show_mask_image(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there the pixel that have multi label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "for col in tqdm_notebook(range(0, len(train_df), 4)):\n",
    "    name, mask = name_and_mask(col)\n",
    "    if (mask.sum(axis=2) >= 2).any():\n",
    "        show_mask_image(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw some chars for input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figures(\n",
    "    sizes,\n",
    "    pie_title,\n",
    "    start_angle,\n",
    "    bar_title,\n",
    "    bar_ylabel,\n",
    "    labels=('Class 1', 'Class 2', 'Class 3', 'Class 4'),\n",
    "    colors=None,\n",
    "    explode=(0, 0, 0, 0.1),\n",
    "):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    y_pos = np.arange(len(labels))\n",
    "    barlist = axes[0].bar(y_pos, sizes, align='center')\n",
    "    axes[0].set_xticks(y_pos, labels)\n",
    "    axes[0].set_ylabel(bar_ylabel)\n",
    "    axes[0].set_title(bar_title)\n",
    "    if colors is not None:\n",
    "        for idx, item in enumerate(barlist):\n",
    "            item.set_color(colors[idx])\n",
    "\n",
    "    def autolabel(rects):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar displaying its height\n",
    "        \"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            axes[0].text(\n",
    "                rect.get_x() + rect.get_width()/2., height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom', fontweight='bold'\n",
    "            )\n",
    "\n",
    "    autolabel(barlist)\n",
    "    \n",
    "    pielist = axes[1].pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=start_angle, counterclock=False)\n",
    "    axes[1].axis('equal')\n",
    "    axes[1].set_title(pie_title)\n",
    "    if colors is not None:\n",
    "        for idx, item in enumerate(pielist[0]):\n",
    "            item.set_color(colors[idx])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[THE WHOLE DATASET]')\n",
    "\n",
    "sum_each_class = np.sum(all_labels, axis=0)\n",
    "plot_figures(\n",
    "    sum_each_class,\n",
    "    pie_title='The percentage of each class',\n",
    "    start_angle=90,\n",
    "    bar_title='The number of images for each class',\n",
    "    bar_ylabel='Images',\n",
    "    colors=COLORS,\n",
    "    explode=(0, 0, 0, 0.1)\n",
    ")\n",
    "\n",
    "sum_each_sample = np.sum(all_labels, axis=1)\n",
    "unique, counts = np.unique(sum_each_sample, return_counts=True)\n",
    "\n",
    "plot_figures(\n",
    "    counts,\n",
    "    pie_title='The percentage of the number of classes appears in an image',\n",
    "    start_angle=120,\n",
    "    bar_title='The number of classes appears in an image',\n",
    "    bar_ylabel='Images',\n",
    "    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n",
    "    explode=np.zeros(len(unique))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(image_files, all_labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[TRAINING SET]')\n",
    "\n",
    "sum_each_class = np.sum(y_train, axis=0)\n",
    "plot_figures(\n",
    "    sum_each_class,\n",
    "    pie_title='The percentage of each class',\n",
    "    start_angle=90,\n",
    "    bar_title='The number of images for each class',\n",
    "    bar_ylabel='Images',\n",
    "    colors=COLORS,\n",
    "    explode=(0, 0, 0, 0.1)\n",
    ")\n",
    "\n",
    "\n",
    "sum_each_sample = np.sum(y_train, axis=1)\n",
    "unique, counts = np.unique(sum_each_sample, return_counts=True)\n",
    "\n",
    "plot_figures(\n",
    "    counts,\n",
    "    pie_title='The percentage of the number of classes appears in an image',\n",
    "    start_angle=120,\n",
    "    bar_title='The number of classes appears in an image',\n",
    "    bar_ylabel='Images',\n",
    "    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n",
    "    explode=np.zeros(len(unique))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some images and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(mask_rle, shape=(1600,256)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(samples):\n",
    "    for sample in samples:\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        img_path = os.path.join(data_path, 'train_images', sample[0])\n",
    "        img = cv2.imread(img_path).copy()\n",
    "\n",
    "        # Get annotations\n",
    "        labels = df[df['ImageId_ClassId'].str.contains(sample[0])]['EncodedPixels']\n",
    "\n",
    "        patches = []\n",
    "        for idx, rle in enumerate(labels.values):\n",
    "            if rle is not np.nan:\n",
    "                mask = rle2mask(rle)\n",
    "                contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for contour in contours:\n",
    "                    poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=1, edgecolor=COLORS[idx], fill=False)\n",
    "                    patches.append(poly_patch)\n",
    "        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet)\n",
    "\n",
    "        ax.imshow(img/255)\n",
    "        ax.set_title('{} - ({})'.format(sample[0], ', '.join(sample[1].astype(np.str))))\n",
    "        ax.add_collection(p)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = np.array(list(zip(X_train, y_train)))\n",
    "train_samples = train_pairs[np.random.choice(train_pairs.shape[0], NUM_TRAIN_SAMPLES, replace=False), :]\n",
    "\n",
    "a=show_samples(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:17.629508Z",
     "start_time": "2020-06-03T12:32:16.851265Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:17.969417Z",
     "start_time": "2020-06-03T12:32:17.629508Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "vis=visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Immitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
    "sample_df = pd.read_csv(os.path.join(data_path,\"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define value tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:17.974420Z",
     "start_time": "2020-06-03T12:32:17.971417Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_tracker(value_plot, value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=value,\n",
    "             win = value_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.011425Z",
     "start_time": "2020-06-03T12:32:17.975418Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_train_info():\n",
    "    fp=train_info_pkl\n",
    "    if False and os.path.exists(fp):\n",
    "        try:\n",
    "            print('loading train data from csv', flush=True)\n",
    "            df_train=pd.read_csv(fp)\n",
    "            print('complete!', flush=True)\n",
    "        except EOFError:\n",
    "            print('EOFError raised.', flush=True)\n",
    "        \n",
    "    else:\n",
    "        df_train=pd.read_csv(data_path+\"/train.csv\")\n",
    "        df_train[\"CAT\"]=df_train[['healthy', 'multiple_diseases', 'rust','scab']].values.argmax(axis=1)\n",
    "        df_train[\"id\"]=df_train[\"image_id\"].apply(lambda x : int(x.split(\"_\")[1]))        \n",
    "        X=df_train['id'].values\n",
    "        y=df_train['CAT'].values\n",
    "        skf=StratifiedKFold(n_splits=5,random_state=22)        \n",
    "        df_train[\"fold\"]=-1\n",
    "        sum=0\n",
    "        for i, (trn_idx,vld_idx) in enumerate(skf.split(X,y)):\n",
    "            df_train.loc[vld_idx,\"fold\"]=i\n",
    "        df_train.to_csv(train_info_pkl,index=False)\n",
    "        \n",
    "    return df_train\n",
    "\n",
    "df_train=read_train_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.019427Z",
     "start_time": "2020-06-03T12:32:18.012426Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "#    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize((img_rows,img_cols),interpolation=Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize((img_rows,img_cols),interpolation=Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.5, 1/0.5, 1/0.5 ]),\n",
    "                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:30:01.941063Z",
     "start_time": "2020-06-02T12:30:01.936064Z"
    }
   },
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, Rotate, Cutout, HorizontalFlip, Normalize\n",
    ")\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "transform_train= Compose([\n",
    "    Rotate(20),\n",
    "    ToTensor()\n",
    "])\n",
    "transform_valid=Compose([\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:07:33.102842Z",
     "start_time": "2020-06-02T12:07:33.100850Z"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.026429Z",
     "start_time": "2020-06-03T12:32:18.020427Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, tr=None):\n",
    "        self.df = df\n",
    "        self.tr=tr\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        name=self.df.iloc[idx].image_id\n",
    "        image_src=img_path+\"/\"+name+\".jpg\"\n",
    "        image = Image.open(image_src)\n",
    "        labels = self.df.iloc[idx].CAT\n",
    "\n",
    "        if self.tr is not None:\n",
    "            image=self.tr(image)\n",
    "        \n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:02:24.344826Z",
     "start_time": "2020-06-02T12:02:24.339825Z"
    }
   },
   "source": [
    "## transforms and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.057437Z",
     "start_time": "2020-06-03T12:32:18.050434Z"
    }
   },
   "outputs": [],
   "source": [
    "sel=1\n",
    "trn_fold=[i for i in range(5) if i not in [sel]]\n",
    "val_fold=[i for i in range(5) if i in [sel]]\n",
    "trn_idx=df_train[df_train.fold.isin(trn_fold)].index\n",
    "val_idx=df_train[df_train.fold.isin(val_fold)].index\n",
    "print(trn_idx.shape,val_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.065438Z",
     "start_time": "2020-06-03T12:32:18.058437Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = PlantDataset(df=df_train.loc[trn_idx],\n",
    "                       tr=transform_train)\n",
    "validset =PlantDataset(df=df_train.loc[val_idx],\n",
    "                      tr=transform_valid)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(validset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,lab in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.069439Z",
     "start_time": "2020-06-03T12:32:18.066438Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.075440Z",
     "start_time": "2020-06-03T12:32:18.070439Z"
    }
   },
   "outputs": [],
   "source": [
    "# conv1x1=resnet.conv1x1\n",
    "# Bottleneck = resnet.Bottleneck\n",
    "# BasicBlock= resnet.BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.093444Z",
     "start_time": "2020-06-03T12:32:18.076439Z"
    }
   },
   "outputs": [],
   "source": [
    "# class ResNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "#         super(ResNet, self).__init__()\n",
    "#         self.inplanes = 16\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
    "#                                bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "#         self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n",
    "#         self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n",
    "        \n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(128 * block.expansion, num_classes)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#         # Zero-initialize the last BN in each residual branch,\n",
    "#         # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "#         # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "#         if zero_init_residual:\n",
    "#             for m in self.modules():\n",
    "#                 if isinstance(m, Bottleneck):\n",
    "#                     nn.init.constant_(m.bn3.weight, 0)\n",
    "#                 elif isinstance(m, BasicBlock):\n",
    "#                     nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "#     def _make_layer(self, block, planes, blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "#             downsample = nn.Sequential(\n",
    "#                 conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "#                 nn.BatchNorm2d(planes * block.expansion),\n",
    "#             )\n",
    "\n",
    "#         layers = []\n",
    "#         layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "#         self.inplanes = planes * block.expansion\n",
    "#         for _ in range(1, blocks):\n",
    "#             layers.append(block(self.inplanes, planes))\n",
    "\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #[-1,3,32,32]\n",
    "#         x = self.conv1(x)\n",
    "#         #x.shape =[1, 16, 32,32]\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         #x = self.maxpool(x)\n",
    "\n",
    "#         x = self.layer1(x)\n",
    "#         #x.shape =[1, 128, 32,32]\n",
    "#         x = self.layer2(x)\n",
    "#         #x.shape =[1, 256, 32,32]\n",
    "#         x = self.layer3(x)\n",
    "#         #x.shape =[1, 512, 16,16]\n",
    "#         x = self.layer4(x)\n",
    "#         #x.shape =[1, 1024, 8,8]\n",
    "        \n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models  as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:19.444325Z",
     "start_time": "2020-06-03T12:32:18.094444Z"
    }
   },
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "num_ftrs=resnet34.fc.in_features\n",
    "resnet34.fc=nn.Linear(num_ftrs,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34=resnet34.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:20.986755Z",
     "start_time": "2020-06-03T12:32:19.451496Z"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.Tensor(1,3,img_rows,img_cols).to(device)\n",
    "out = resnet34(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:20.991754Z",
     "start_time": "2020-06-03T12:32:20.987754Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss().to(device)\n",
    "optimizer=torch.optim.SGD(resnet34.parameters(),lr=1e-2,momentum=0.9,weight_decay=5e-4)\n",
    "lr_sched=optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:21.007757Z",
     "start_time": "2020-06-03T12:32:20.992755Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),\n",
    "                    opts=dict(title='loss_tracker', \n",
    "                              legend=['loss'], \n",
    "                              showlegend=True))\n",
    "acc_plt = vis.line(Y=torch.Tensor(1).zero_(),\n",
    "                   opts=dict(title='Accuracy', \n",
    "                             legend=['Acc'],\n",
    "                             showlegend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define acc check func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:21.015760Z",
     "start_time": "2020-06-03T12:32:21.009758Z"
    }
   },
   "outputs": [],
   "source": [
    "best_acc=0\n",
    "def acc_check(net, test_set, epoch, save=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    global best_acc\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    acc = (100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % acc)\n",
    "    if save and best_acc<acc:\n",
    "        best_acc=acc\n",
    "        torch.save(net.state_dict(), file_path+\"_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T13:08:46.110268Z",
     "start_time": "2020-06-03T12:38:43.415679Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(len(train_loader))\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    lr_sched.step()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet34(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(train_loader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Check Accuracy\n",
    "    acc = acc_check(resnet34, valid_loader, epoch, save=1)\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T13:09:17.294174Z",
     "start_time": "2020-06-03T13:09:17.278550Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:31.468763Z",
     "start_time": "2020-06-03T12:32:16.001Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.current_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:31.469763Z",
     "start_time": "2020-06-03T12:32:16.002Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:31.470764Z",
     "start_time": "2020-06-03T12:32:16.004Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
