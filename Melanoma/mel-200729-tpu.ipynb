{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Version 12 GPU / Resnext 32x4d / 89% / basic aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install xgboost\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import load_iris\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest= pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\nsub   = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sex'] = train['sex'].fillna('na')\ntrain['age_approx'] = train['age_approx'].fillna(0)\ntrain['anatom_site_general_challenge'] = train['anatom_site_general_challenge'].fillna('na')\n\ntest['sex'] = test['sex'].fillna('na')\ntest['age_approx'] = test['age_approx'].fillna(0)\ntest['anatom_site_general_challenge'] = test['anatom_site_general_challenge'].fillna('na')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sex'] = train['sex'].astype(\"category\").cat.codes +1\ntrain['anatom_site_general_challenge'] = train['anatom_site_general_challenge'].astype(\"category\").cat.codes +1\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sex'] = test['sex'].astype(\"category\").cat.codes +1\ntest['anatom_site_general_challenge'] = test['anatom_site_general_challenge'].astype(\"category\").cat.codes +1\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train[['sex', 'age_approx','anatom_site_general_challenge']]\ny_train = train['target']\n\n\nx_test = test[['sex', 'age_approx','anatom_site_general_challenge']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier(n_estimators=2000, \n                        max_depth=8, \n                        objective='multi:softprob',\n                        seed=0,  \n                        nthread=-1, \n                        learning_rate=0.15, \n                        num_class = 2, \n                        scale_pos_weight = (32542/584))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.target = clf.predict_proba(x_test)[:,1]\nsub.to_csv(\"./sub_xgboost_0817.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TPU\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n!pip install wtfml==0.0.3\n!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm \nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils\nimport warnings\nimport gc\nfrom wtfml.utils import EarlyStopping\nfrom sklearn.metrics import roc_auc_score\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision\n\nimport cv2\n\nimport numpy as np \nimport pandas as pd\nimport os\n\nfrom torch.utils.data import DataLoader,TensorDataset,Dataset\nimport matplotlib.pyplot as plt\nimport albumentations\nfrom sklearn import model_selection\nfrom sklearn.metrics import roc_auc_score\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nclass Effi(nn.Module):\n    def __init__(self):\n        super(Effi, self).__init__()\n        self.base_model = EfficientNet.from_pretrained(\n            'efficientnet-b4'\n        )\n        self.base_model._fc = nn.Linear(\n            in_features=1792, \n            out_features=1, \n            bias=True\n        )\n        \n    def forward(self, image):\n        out = self.base_model(image)\n#         loss = nn.BCEWithLogitsLoss()(out, targets.view(-1, 1).type_as(out))\n        return out#, loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## New TPU Model\nclass EffNet(nn.Module):\n    def __init__(self,model='b4'):\n        super(EffNet,self).__init__()\n        \n        model_name = 'efficientnet' + model\n        self.feature = EfficientNet.from_pretrained(\"efficientnet-b4\")\n        self.drop = nn.Dropout(0.3)\n        self.l0 = nn.Linear(1792,1) # b3 - 1536 b2 - 1408\n        \n        \n    def forward(self,img):\n        batch_size = img.shape[0]\n        \n        x = self.feature.extract_features(img)\n        #print(x.shape)\n        \n        x = nn.functional.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        #print(x.shape)\n        \n        x = self.drop(x)\n        #print(x.shape)\n        out = self.l0(x)\n        #print(out.shape)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_csv():\n    df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\n    df[\"fold\"] = -1    \n    df = df.sample(frac=1).reset_index(drop=True)\n    y = df.target.values\n    kf = model_selection.StratifiedKFold(n_splits=5)\n\n    for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n        df.loc[v_, 'fold'] = f\n\n    df.to_csv(\"train_kfold.csv\", index=False)\n    return df\ndf=make_csv()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Augmentation\nfrom albumentations import ( HorizontalFlip, IAAPerspective, ShiftScaleRotate, \nCLAHE, RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion, \nGridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, \nMotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine, IAASharpen, \nIAAEmboss, Flip, OneOf, Compose, Rotate, Cutout, HorizontalFlip, Normalize ) \n\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndef get_aug(mode=\"train\"):\n    if mode ==\"train\":\n        aug=Compose([Rotate(15),\n            OneOf([IAAAdditiveGaussianNoise(),GaussNoise(),], p=0.2),\n            #OneOf([MotionBlur(p=0.2),MedianBlur(blur_limit=3, p=0.1),Blur(blur_limit=3, p=0.1),], p=0.2),\n            ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.2),\n            OneOf([OpticalDistortion(p=0.3),GridDistortion(p=0.1),IAAPiecewiseAffine(p=0.3),], p=0.2),\n            OneOf([\n                CLAHE(clip_limit=2),\n                IAASharpen(),\n                IAAEmboss(),\n                RandomBrightnessContrast(),\n            ], p=0.3),\n            HueSaturationValue(p=0.3),\n            Flip(0.5),\n            HorizontalFlip(0.5),\n            Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n            ])\n    else:\n        aug=Compose([Normalize(mean, std, max_pixel_value=255.0, always_apply=True),])\n\n    return aug  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nclass ClassificationLoader:\n    def __init__(self, image_paths, targets, resize, augmentations=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        targets = self.targets[item]\n\n        image = np.array(image)\n        image = self.augmentations(image=image)[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return torch.tensor(image, dtype=torch.float),torch.tensor(targets, dtype=torch.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset\ntrain_bs=108\nvalid_bs=64\ndef get_dataset(df,mode=\"train\",path=None):\n    imgs=df.image_name.values.tolist()\n    imgs=[path+file+\".jpg\" for file in imgs]\n    if mode ==\"test\":\n        tar=np.zeros(len(imgs))\n    else:\n        tar=df.target.values\n\n    aug=get_aug(mode)\n\n    dataset=ClassificationLoader(\n        image_paths=imgs,targets=tar,resize=None,augmentations=aug\n    )\n\n    batch_size = train_bs if mode==\"train\" else valid_bs\n    shuffle=True if mode==\"train\" else False\n    \n    sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n                                                                  num_replicas = xm.xrt_world_size(),\n                                                                  rank = xm.get_ordinal(),\n                                                                  shuffle = shuffle)\n    dataloader = torch.utils.data.DataLoader(dataset,\n                                             batch_size=batch_size,\n                                             shuffle=False,\n                                             sampler=sampler,\n                                             num_workers=4)\n    return dataloader,tar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nclass Engine:\n    @staticmethod\n    def train(\n        data_loader,\n        model,\n        optimizer,\n        device,\n        epoch,\n        criterion\n    ):\n        \n        losses = AverageMeter()\n        predictions = []\n        model.train()\n        \n#         para_loader = pl.ParallelLoader(data_loader, [device])\n#         tk0 = para_loader.per_device_loader(device)\n        tk0 = tqdm(data_loader, total=len(data_loader), disable=False, ascii=True)\n        for b_idx, (image,targets) in enumerate(tk0):\n            image=image.to(device)\n            targets = targets.to(device)\n            optimizer.zero_grad()\n            out = model(image)\n            loss=criterion(out,targets.unsqueeze(1).type_as(out))\n            del image,targets\n            gc.collect()\n            \n            losses.update(loss.item(), data_loader.batch_size)\n            loss.backward()\n            xm.optimizer_step(optimizer, barrier=True)\n\n        tk0.set_postfix(loss=losses.avg)\n        return losses.avg\n\n    @staticmethod\n    def evaluate(data_loader, model, device, use_tpu=False):\n        losses = AverageMeter()\n        final_predictions = []\n        model.eval()\n        with torch.no_grad():\n            tk0 = tqdm(data_loader, total=len(data_loader), ascii=True)\n            for b_idx, (image,targets) in enumerate(tk0):\n                image=image.to(device)\n                targets = targets.to(device)\n\n                predictions = model(image)\n                predictions = predictions.cpu()\n\n                del image,targets\n                gc.collect()\n                final_predictions.append(predictions)\n        return final_predictions, losses.avg\n\n    @staticmethod\n    def predict(data_loader, model, device, use_tpu=False):\n        model.eval()\n        final_predictions = []\n        with torch.no_grad():\n            tk0 = tqdm(data_loader, total=len(data_loader), ascii=True)\n            for b_idx, (image,targets) in enumerate(tk0):\n                image=image.to(device)\n                predictions = model(image)\n                predictions = predictions.cpu()\n\n                del image,targets\n                gc.collect()\n\n                final_predictions.append(predictions)\n        return final_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model,fold):\n    df=pd.read_csv(\"/kaggle/working/train_kfold.csv\")\n    device = xm.xla_device() \n    epochs=20\n\n    df_train=df[df.fold!=fold].reset_index(drop=True)\n    df_valid=df[df.fold==fold].reset_index(drop=True)\n\n    path=\"../input/simm-isic-224-224/train3/\"\n    train_loader,train_tar=get_dataset(df_train,\"train\",path=path)\n    valid_loader,valid_tar=get_dataset(df_valid,\"valid\",path=path)\n \n#     model = Effi()\n    model=model.to(device)\n\n    optimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\n    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,patience=3,threshold=0.001,mode=\"max\",\n    )\n    es=EarlyStopping(patience=3,mode=\"max\",tpu=True)\n    criterion = nn.BCEWithLogitsLoss()\n\n    for epoch in range(epochs):\n        train_loss=Engine.train(train_loader, model, optimizer, device, epoch, criterion)\n        preds,valid_loss=Engine.evaluate(valid_loader,model, device)\n        preds=np.vstack(preds).flatten()\n        auc=roc_auc_score(valid_tar,preds)\n        print(f\"Epoch:{epoch}, AUC: {auc}\")\n        scheduler.step(auc)\n        es(auc,model,model_path=f\"model_fold_{fold}.bin\")\n        if es.early_stop:\n            print(\"early stop\")\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Effi()\n# train(model,0)\nmodel = Effi()\ntrain(model,1)\nmodel = Effi()\ntrain(model,2)\nmodel = Effi()\ntrain(model,3)\nmodel = Effi()\ntrain(model,4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def predict_uploaded(fold):\n    \n    df=pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\n    device = xm.xla_device() \n\n    path=\"../input/simm-isic-224-224/test3/\"\n    test_loader,_ = get_dataset(df,\"test\",path=path)\n\n    model=Effi()\n    model_save_path=f\"../input/model-fold-0bin/model_fold_0.bin\"\n    model.load_state_dict(torch.load(model_save_path))\n    model=model.to(device)\n\n    preds=Engine.predict(test_loader,model, device)\n    preds=np.vstack(preds).flatten()\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(fold):\n    \n    df=pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\n    device = xm.xla_device() \n\n    path=\"../input/simm-isic-224-224/test3/\"\n    test_loader,_ = get_dataset(df,\"test\",path=path)\n\n    model=Effi()\n    model_save_path=f\"./model_fold_{fold}.bin\"\n    model.load_state_dict(torch.load(model_save_path))\n    model=model.to(device)\n\n    preds=Engine.predict(test_loader,model, device)\n    preds=np.vstack(preds).flatten()\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = predict_uploaded(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\np2 = predict(1)\np3 = predict(2)\np4 = predict(3)\np5 = predict(4)\n\npredictions = (p1 + p2 + p3 + p4 + p5) / 5\nsample = pd.read_csv(\"../input/siim-isic-melanoma-classification/sample_submission.csv\")\nsample.loc[:, \"target\"] = predictions\nsample.to_csv(\"sub_effi_b4_200817.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nsub_resnext=pd.read_csv(\"../input/essenble/sub_200807_resnext_89.csv\")\nsub_xg=pd.read_csv(\"../input/essenble/sub_xgboost_0817.csv\")\nsub_effi=pd.read_csv(\"../input/essenble2/sub_effi_b4_200817.csv\")\nsample = pd.read_csv(\"../input/siim-isic-melanoma-classification/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1=sub_resnext.target.values\np2=sub_xg.target.values\np3=sub_effi.target.values\np=p1*0.45+p2*0.1+p3*0.45\nsample.loc[:, \"target\"] = p\nsample.to_csv(\"sub_essenble_200817.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_effi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}