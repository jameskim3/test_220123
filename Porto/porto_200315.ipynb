{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv(\"data/train.csv\",na_values=[\"-1\",\"-1.0\"])\n",
    "test=pd.read_csv(\"data/test.csv\",na_values=[\"-1\",\"-1.0\"])\n",
    "\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.target.sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "          'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_calc_15_bin', \n",
    "          'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n",
    "# 범주형 변수\n",
    "category = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', \n",
    "            'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', \n",
    "            'ps_car_10_cat', 'ps_car_11_cat']\n",
    "# 정수형 변수\n",
    "integer = ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06', \n",
    "           'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', \n",
    "           'ps_calc_14', 'ps_car_11']\n",
    "# 소수형 변수\n",
    "floats = ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_car_12', 'ps_car_13',\n",
    "          'ps_car_14', 'ps_car_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단일변수 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"]=np.nan\n",
    "all_data=pd.concat([train,test],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(col,data,hue=None):\n",
    "    f,ax=plt.subplots(figsize=(10,5))\n",
    "    sns.countplot(x=col,hue=hue,data=data,alpha=0.5)\n",
    "    plt.show()\n",
    "def dist_plot(col,data):\n",
    "    f,ax=plt.subplots(figsize=(10,5))\n",
    "    sns.distplot(data[col].dropna(),kde=False,bins=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary+category+integer:\n",
    "    bar_plot(col,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in floats:\n",
    "    dist_plot(col,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수간 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=all_data.corr()\n",
    "cmap=sns.color_palette(\"Blues\")\n",
    "f,ax=plt.subplots(figsize=(10,7))\n",
    "sns.heatmap(corr,cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', \n",
    "          'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin',\n",
    "          'ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', \n",
    "          'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', \n",
    "          'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_car_11',\n",
    "          'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_12', 'ps_car_13',\n",
    "          'ps_car_14', 'ps_car_15']\n",
    "\n",
    "corr_sub=all_data[features].corr()\n",
    "f,ax=plt.subplots(figsize=(10,7))\n",
    "sns.heatmap(corr_sub,cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ps_ind_14와 ps_ind_12_bin은 강한 상관관계를 가진다\n",
    "- **95%이상의 강한 상관관계가 없으므로 뺄 데이터는 없다.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단일 변수 vs 타겟 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bar_plot_ci(col,data):\n",
    "    f,ax=plt.subplots(figsize=(10,5))\n",
    "    sns.barplot(x=col,y=\"target\",data=data)\n",
    "    plt.show()\n",
    "    \n",
    "for col in binary+category+integer:\n",
    "    bar_plot_ci(col,all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 데이터 기준 타겟 변수의 비율은 3.6%이다. 이 점을 감안하며 함께 분석해 보자. 막대 그래프 중간에 그려진 검정색 직선은 95% 신뢰구간을 의미한다.\n",
    "#### ps_ind_16_bin,ps_ind_06_bin 두변수는 이진 변수의 값에 따라 타겟 변수의 비율이 다르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar=[\"ps_ind_16_bin\",\"ps_ind_06_bin\",\"ps_ind_11_bin\",\"ps_calc_18_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tar:\n",
    "    bar_plot_ci(col,all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ps_ind_16_bin,ps_ind_06_bin 두 변수는 이진 변수 값에 따라 타겟 변수의 비율이 다르다. 통계적 유효성을 충분히 지니고 있는 두 변수는 모델링 관점에서 유용하다. \n",
    "2. 반면 ps_ind_11_bin은 평균적으로는 다르게 보이지만 통계적으로 유효성이 없다. \n",
    "3. ps_calc_18은 target변수의 값이 큰 차이가 없으므로 유효한 변수가 아니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ps_car_01_cat 변수는 7,8 값이 타겟 비율이 다르다. 따라서 의미가 있다. 1과2는 타겟 비율의 95% 신뢰구간이 넓어 변수로써 예측능력이 월등하지는 않다. \n",
    "2. ps_car_11_cat 변수는 104개의 고유값이 0.02~0.08의 큰 범위의 타겟 비율을 보인다. 따라서 의미가 있다.\n",
    "3. ps_calc_06,ps_calc_07 변수는 특정 값에서의 95% 신뢰구간이 너무 광범위해서 예측 능력은 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', \n",
    "            'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', \n",
    "            'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', \n",
    "            'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', \n",
    "            'ps_ind_03', 'ps_ind_15', 'ps_car_11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 위 값이 단일 변수로써 의미가 있는 변수들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련데이터 vs 테스트데이터 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"is_tst\"]=all_data[\"target\"].isnull()\n",
    "for col in binary+category+integer:\n",
    "    bar_plot(col,all_data,\"is_tst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"target\"].isnull().sum(),all_data.shape[0],train.shape[0],test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 모든 데이터 들이 트레인 데이터와 테스트 데이터 비율이 유사하다. 타겟이 null인 변수는 test변수이다. hue로 null 설정되었으므로 false는 트레인, true는 테스트이다. 모든 변수들이 1:1.5의 비율을 유지하고 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 탐색적 데이터 분석 요약\n",
    "+ 모든 데이터는 정수, 소수형 타입이라서 바로 모델을 적용할 수 있다.\n",
    "+ 57개의 변수는 모두 익명화 되어 있다.\n",
    "+ 전처리 과정으로 정보력이 아예 없는 상수값 혹은 0.95 이상의 높은 상관관계를 가지는 중복 변수등은 존재하지 않는다.\n",
    "+ 변수의 예측 능력을 가늠하기 위해서 변수 고유값별 타겟 변수의 비율을 신뢰구간 95%와 함께 분석해 보았다. 의미있는 항목을 선별할 수 있다.\n",
    "- 훈련 데이터와 테스트 데이터를 비교해 보았는데, 데이터 분포으 차이는 없었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- baseline 모델 pipeline을 구축하는 방법은 다음과 같다\n",
    "    - 데이터 전처리, 피처 엔지니어링, 학습 모델 정의, 모델 학습 및 교차 검증 평가, 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/train.csv\")\n",
    "y_train=train[\"target\"]\n",
    "train_id=train.id\n",
    "del train[\"target\"],train[\"id\"]\n",
    "\n",
    "test=pd.read_csv(\"data/test.csv\")\n",
    "test_id=test.id\n",
    "del test[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 피처 엔지니어링\n",
    "+ eda를 통해서 얻은 데이터를 적극 활용한다면 유의미한 파생 변수를 생성할 수 있다.\n",
    "+ 3가지 기초 피처 엔지니어링을 수행한다.\n",
    "    - 결측값의 개수를 나타내는 missing 변수\n",
    "    - 이진변수들의 총합\n",
    "    - target encoding 파생변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"missing\"]=(train==-1).sum(axis=1).astype(float)\n",
    "test[\"missing\"]=(train==-1).sum(axis=1).astype(float)\n",
    "\n",
    "bin_features=[c for c in train.columns if 'bin' in c]\n",
    "train[\"bin_sum\"]=train[bin_features].sum(axis=1)\n",
    "test[\"bin_sum\"]=test[bin_features].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', \n",
    "            'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', \n",
    "            'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', \n",
    "            'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', \n",
    "            'ps_ind_03', 'ps_ind_15', 'ps_car_11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 첫번째 파생 변수는 nan값을 더한 것이다. 독자는 의야해 할 수도 있지만, 과거 경진대회에서 효자로 작용한 적이 종종 있다.\n",
    "+ 두번째 파생 변수는 이진 변수의 합이다. 변수 간의 상호 작용으로 얻을 수 있는 고차원 정보를 추출한다.\n",
    "+ 세 번재 파생 변수는 데이터 탐색 분석 과정에서 선별한 일부 변수들을 대상으로 Target encoding을 수행한다.\n",
    "    + 예를들어 ps_ind_01 변수가 0일 경우 ps_ind_01 변수가 0인 모든 운전자들의 평균 타겟값을 ps_ind_01_enc 파생변수로 생성하는 것이다.\n",
    "        - 타겟 변수의 값을 직접적으로 사용하는 변수이기 때문에 데이터 유출로 이어져 모델 파이프라인을 망칠 수 있다\n",
    "        - 데이터 유출을 방지하기 위해서, 5-fold 내부 교차 검증 과정에서 학습에 사용되는 4/5 훈련 데이터로 변수 고유값별 평균 타겟 계산\n",
    "        - 1/5의 검증 데이터에 해당 값을 매핑하는 방식을 취한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) LightBGM 모델 정의\n",
    "+ num_leaves, max_bin,min_child_samples 설정으로 모델 복잡도를조절\n",
    "+ feature_fraction, subsample,max_drop 설정값으로 과적합을 방지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 15,\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.6,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9,\n",
    "          \"seed\": 2018\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 모델 학습 및 교차 검증 평가\n",
    "+ 교차검증은 5-fold StratifiedKFold 기법을 사용한다.\n",
    "+ 시계열 데이터가 아니므로 제공된 데이터를 랜덤하게 분리하여 교차 검증\n",
    "+ 재현성을 위하여 random_state를 고정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "NFOLDS=5\n",
    "kfold=StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "kf=kfold.split(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train=np.zeros(len(y_train))\n",
    "cv_pred=np.zeros(len(test_id))\n",
    "best_trees=[]\n",
    "fold_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold,kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(train_fold,validate) in enumerate(kf):\n",
    "    x_train,x_validate,label_train,label_validate=\\\n",
    "    train.iloc[train_fold,:],train.iloc[validate,:],y_train[train_fold],y_train[validate]\n",
    "    \n",
    "    for feature in features:\n",
    "        map_dic=pd.DataFrame([x_train[feature],label_train]).T.groupby(feature).agg('mean')\n",
    "        map_dic=map_dic.to_dict()[\"target\"]\n",
    "        x_train[feature+\"_target_enc\"]=x_train[feature].apply(lambda x:map_dic.get(x,0))\n",
    "        x_validate[feature+\"_target_enc\"]=x_validate[feature].apply(lambda x : map_dic.get(x,0))\n",
    "        test[feature+\"_target_end\"]=test[feature].apply(lambda x:map_dic.get(x,0))\n",
    "\n",
    "    dtrain=lgbm.Dataset(x_train,label_train)\n",
    "    dvalid=lgbm.Dataset(x_validate,label_validate,reference=dtrain)\n",
    "\n",
    "    bst=lgbm.train(params,dtrain,num_boost_round,valid_sets=dvalid,feval=evalerror,verbose_eval=100,early_stopping_rounds=100)\n",
    "    best_trees.append(bst.best_iteration)\n",
    "    cv_pred+= bst.predict(test,num_iteration=bst.best_iteration)\n",
    "    cv_train[validate] += bst.predict(x_validate)\n",
    "    \n",
    "    score=Gini(label_validate,cv_train[validate])\n",
    "    print(score)\n",
    "    fold_scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pred/=NFOLDS\n",
    "\n",
    "print(\"cv score:\")\n",
    "print(Gini(y_train,cv_train))\n",
    "print(fold_scores)\n",
    "print(best_trees,np.mean(best_trees))\n",
    "\n",
    "pd.DataFrame({\"id\":test_id,\"target\":cv_pred}).to_csv(\"Data/lgbm_baseline.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
