{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from  scipy.stats import norm,skew\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/train.csv\",parse_dates=[2], low_memory=False)\n",
    "test=pd.read_csv(\"data/test.csv\",parse_dates=[3],low_memory=False)\n",
    "store=pd.read_csv(\"data/store.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01 00:00:00 2015-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Date\"].min(),train[\"Date\"].max())\n",
    "train.sort_values([\"Date\"],inplace=True, kind=\"mergesort\")\n",
    "train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Open\"]=test[\"Open\"].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                        0.000000\n",
       "StoreType                    0.000000\n",
       "Assortment                   0.000000\n",
       "CompetitionDistance          0.002691\n",
       "CompetitionOpenSinceMonth    0.317489\n",
       "CompetitionOpenSinceYear     0.317489\n",
       "Promo2                       0.000000\n",
       "Promo2SinceWeek              0.487892\n",
       "Promo2SinceYear              0.487892\n",
       "PromoInterval                0.487892\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.isnull().sum()/store.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.merge(train,store,on=\"Store\",how=\"left\")\n",
    "test=pd.merge(test,store,on=\"Store\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df[\"year\"]=df.Date.dt.year\n",
    "    df[\"month\"]=df.Date.dt.month\n",
    "    df[\"day\"]=df.Date.dt.day\n",
    "    df[\"day\"]=df.Date.dt.day\n",
    "    assert np.all(df.DayOfWeek-1==df[\"Date\"].dt.dayofweek)\n",
    "    df[\"dayofyear\"]=df.Date.dt.dayofyear\n",
    "    df[\"weekofyear\"]=df.Date.dt.weekofyear\n",
    "    df.drop(\"Date\",axis=1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df[\"CompetitionOpen\"]=((df[\"year\"]-df[\"CompetitionOpenSinceYear\"])*12 \n",
    "                          + (df[\"month\"]-df[\"CompetitionOpenSinceMonth\"]))\n",
    "    df[\"CompetitionOpen\"]=df[\"CompetitionOpen\"].apply(lambda x : x if x>0 else 0)\n",
    "    df[\"PromoOpen\"]=((df[\"year\"]-df[\"Promo2SinceYear\"]) * 12\n",
    "                     + (df[\"weekofyear\"]-df[\"Promo2SinceWeek\"])/4)\n",
    "    df[\"PromoOpen\"]=df[\"PromoOpen\"].apply(lambda x : x if x>0 else 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "def check(row):\n",
    "    if isinstance(row[\"PromoInterval\"],str) and month2str[row[\"month\"]] in row[\"PromoInterval\"]:\n",
    "        if (row[\"year\"] > row[\"Promo2SinceYear\"] or\n",
    "            (row['year'] == row['Promo2SinceYear'] and row['weekofyear'] > row['Promo2SinceWeek'])):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "for df in [train,test]:\n",
    "    df[\"IsPromoMonth\"]=df.apply(lambda row:check(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train은 Open 평균이 의미가 있으나, test는 Open 평균이 모두 같으므로 train의 opne 평균을 test에도 적용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "groups=train[[\"Store\",\"Open\"]].groupby(\"Store\").mean()\n",
    "groups.rename(columns={\"Open\":\"shopavgopen\"},inplace=True)\n",
    "train = pd.merge(train, groups, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, groups, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=train[[\"Store\",\"Sales\",\"Customers\"]].groupby(\"Store\").sum()\n",
    "groups[\"ShopAvgSalePerCustomer\"]=groups[\"Sales\"]/groups[\"Customers\"]\n",
    "del groups[\"Sales\"],groups[\"Customers\"]\n",
    "train = pd.merge(train, groups, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, groups, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=train[[\"Store\",\"SchoolHoliday\"]].groupby(\"Store\").mean()\n",
    "groups.columns=[\"ShopAvgSchoolHoliday\"]\n",
    "train = pd.merge(train, groups, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, groups, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo',\n",
       "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
       "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
       "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
       "       'Promo2SinceYear', 'PromoInterval', 'year', 'month', 'day', 'dayofyear',\n",
       "       'weekofyear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth',\n",
       "       'shopavgopen', 'ShopAvgSalePerCustomer', 'ShopAvgSchoolHoliday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups1=train[[\"Store\",\"Sales\"]].groupby(\"Store\").sum()\n",
    "groups2=train[train[\"StateHoliday\"]==1][[\"Store\",\"Sales\"]].groupby(\"Store\").sum()\n",
    "groups=pd.merge(groups1,groups2,on=\"Store\")\n",
    "groups[\"ShopSalesHoliday\"]=groups[\"Sales_y\"]/groups[\"Sales_x\"]\n",
    "del groups[\"Sales_x\"],groups[\"Sales_y\"]\n",
    "train = pd.merge(train, groups, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, groups, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups1=train[[\"Store\",\"Sales\"]].groupby(\"Store\").sum()\n",
    "groups2=train[train[\"IsPromoMonth\"]==1][[\"Store\",\"Sales\"]].groupby(\"Store\").sum()\n",
    "groups=pd.merge(groups1,groups2,on=\"Store\")\n",
    "groups[\"ShopSalesPromo\"]=groups[\"Sales_y\"]/groups[\"Sales_x\"]\n",
    "del groups[\"Sales_x\"],groups[\"Sales_y\"]\n",
    "train = pd.merge(train, groups, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, groups, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups1=train[[\"Store\",\"Sales\"]].groupby(\"Store\").sum()\n",
    "groups2=train[train[\"DayOfWeek\"]==6][[\"Store\",\"Sales\"]].groupby(\"Store\").sum()\n",
    "groups=pd.merge(groups1,groups2,on=\"Store\")\n",
    "groups[\"ShopSalesSaturday\"]=groups[\"Sales_y\"]/groups[\"Sales_x\"]\n",
    "del groups[\"Sales_x\"],groups[\"Sales_y\"]\n",
    "train = pd.merge(train, groups, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, groups, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(train[train.Open==0][\"Sales\"]==0)\n",
    "train=train[train[\"Sales\"]!=0]\n",
    "del train[\"Open\"]\n",
    "test_close_ind=np.where(test[\"Open\"]==0)[0]\n",
    "del test[\"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"StateHoliday\", \"StoreType\", \"Assortment\", \"DayOfWeek\", \"month\", \"PromoInterval\"]:\n",
    "    for val in train[col].unique():\n",
    "        new_col_name=col+\"_\"+str(val)\n",
    "        train[new_col_name]=(train[col]==val).astype(int)\n",
    "        test[new_col_name]=(test[col]==val).astype(int)\n",
    "del train[\"PromoInterval\"],test[\"PromoInterval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"StateHoliday\",\"StoreType\",\"Assortment\"]:\n",
    "    le=LabelEncoder()\n",
    "    train[col]=le.fit_transform(train[col])\n",
    "    test[col]=le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(train.Sales)\n",
    "train.drop(\"Sales\",axis=1,inplace=True)\n",
    "train.drop(\"Customers\",axis=1,inplace=True)\n",
    "test_id=test[\"Id\"]\n",
    "test.drop(\"Id\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true,y_pred):\n",
    "    y_pred=y_pred[y_pred!=0]\n",
    "    y_true=y_true[y_true!=0]\n",
    "    err=np.sqrt(np.mean((1-y_pred/y_true)**2))\n",
    "    return err\n",
    "def rmspe_xgb(y_pred,y_true):\n",
    "    y_true=y_true.get_label()\n",
    "    err=rmspe(np.expm1(y_true),np.expm1(y_pred))\n",
    "    return \"rmspe\",err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:5.79232\tvalidation_1-rmse:5.80251\tvalidation_0-rmspe:0.99686\tvalidation_1-rmspe:0.99691\n",
      "Multiple eval metrics have been passed: 'validation_1-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmspe hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:0.08457\tvalidation_1-rmse:0.12249\tvalidation_0-rmspe:0.10492\tvalidation_1-rmspe:0.12838\n",
      "[200]\tvalidation_0-rmse:0.07116\tvalidation_1-rmse:0.12150\tvalidation_0-rmspe:0.07798\tvalidation_1-rmspe:0.12735\n",
      "[300]\tvalidation_0-rmse:0.06330\tvalidation_1-rmse:0.12197\tvalidation_0-rmspe:0.06574\tvalidation_1-rmspe:0.12740\n",
      "Stopping. Best iteration:\n",
      "[251]\tvalidation_0-rmse:0.06677\tvalidation_1-rmse:0.12153\tvalidation_0-rmspe:0.06996\tvalidation_1-rmspe:0.12700\n",
      "\n",
      "ellapse 152.40242409706116\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "valid_mask=(train.year==2015) & (train.dayofyear>=171)\n",
    "train1,y_train1=train[~valid_mask],y_train[~valid_mask]\n",
    "train2,y_train2=train[valid_mask],y_train[valid_mask]\n",
    "reg=xgb.XGBRegressor(n_estimators=5000,objective=\"reg:squarederror\",max_depth=10,\n",
    "                    learning_reate=0.03,colsample_bytree=0.7,subsample=0.9,\n",
    "                    random_state=0, tree_method=\"gpu_hist\")\n",
    "reg.fit(train1,y_train1,eval_set=[(train1,y_train1),(train2,y_train2)],\n",
    "       eval_metric=rmspe_xgb,early_stopping_rounds=100,verbose=100)\n",
    "best_iteration=reg.best_iteration\n",
    "print(\"ellapse\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.expm1(reg.predict(test))\n",
    "pred[test_close_ind]=0\n",
    "submission=pd.DataFrame({\"Id\":test_id,\"Sales\":pred},columns=[\"Id\",\"Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now=datetime.now()\n",
    "submission.to_csv(\"data/{0:02d}{1:02d}{2:02d}{3:02d}_ensemble_submission.csv\".format(now.year,now.month,now.day,now.hour),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6384"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.28**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14350590372388738"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "474/3303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
