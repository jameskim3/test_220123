{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Notebook Version\n**- ver6. 9/26, 0.95734 :** \n    - Aug 수정(Peter), 224, Model:B4, DenseCrossEntropy(nn.Module)\n    - 5-Fold, Random-No,개별 Softmax -> 합 softmax\n    \n**- ver7. 9/27, 0.95912 :** \n    - nn.CrossEntropyLoss()\n\n**- ver8. 9/28,0.94741 :**\n    - Aug 수정(Akash)\n    - Model:B5, Linear+ ReLU + Dropout\n    - Train Info Graph\n**- ver11. 9/28,000 :**\n    - Ver7로 복귀\n    - B0~B7 평가 (7->0):  7:0.183,6:0.1880,5: 0.194,4 0.160,3 0.189,2 0.176, 1 0.179,0 0.169    \n    \n**- ver13. 10/3,0.95860 :**\n    - Focal Loss\n    \n**- ver13./ver3 10/4,0.95860 :**\n    - Focal Loss 1,2,3\n    - model 4ea(efficientnet, resnet50,densenet, inception)\n**- ver14./ver3 10/4,0.95860 :**\n    - cutmix, focal loss3"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name=\"effinet\"\nversion_info=\"v14\"\ndef get_model(model_name):\n    if model_name==\"effinet\": return EffiNet()\n    if model_name==\"resnet\": return Resnet50()    \n    if model_name==\"densenet\": return Densenet()    \n    if model_name==\"effinet7\": return EffiNet7()    ","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action='ignore') \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/train-fold/train_fold.csv\")\ntest=pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/test.csv\")\nsample_submission=pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch","execution_count":4,"outputs":[{"output_type":"stream","text":"Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.0.tar.gz (20 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.6.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.5)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-py3-none-any.whl size=16035 sha256=7dd79960ea301ccafa6b352f5b4187be18199261716ceb81c22b7959b30da580\n  Stored in directory: /root/.cache/pip/wheels/b7/cc/0d/41d384b0071c6f46e542aded5f8571700ace4f1eb3f1591c29\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nclass ClassificationLoader:\n    def __init__(self, image_paths, targets, resize, augmentations=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        targets = self.targets[item]\n\n        image = np.array(image)\n        if self.augmentations:\n            image = self.augmentations(image=image)[\"image\"]\n        return {\n            \"img\":torch.tensor(image, dtype=torch.float),\n            \"tar\":torch.tensor(targets, dtype=torch.long)\n        }","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.dataset import Dataset\nclass CutMix(Dataset):\n    def __init__(self, dataset, num_class, num_mix=1, beta=1., prob=0.5):\n        self.dataset = dataset\n        self.num_class = num_class\n        self.num_mix = num_mix\n        self.beta = beta\n        self.prob = prob\n        \n    def rand_bbox(self, size, lam):\n        if len(size) == 4:\n            W = size[2]\n            H = size[3]\n        elif len(size) == 3:\n            W = size[1]\n            H = size[2]\n        else:\n            raise Exception\n\n        cut_rat = np.sqrt(1. - lam)\n        cut_w = np.int(W * cut_rat)\n        cut_h = np.int(H * cut_rat)\n\n        # uniform\n        cx = np.random.randint(W)\n        cy = np.random.randint(H)\n\n        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n        bby1 = np.clip(cy - cut_h // 2, 0, H)\n        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n        bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n        return bbx1, bby1, bbx2, bby2\n\n    def onehot(self,size, target):\n        vec = torch.zeros(size, dtype=torch.float32)\n        vec[target] = 1.\n        return vec\n    \n    def __getitem__(self, index):\n        data=self.dataset[index]\n        img, lb = data[\"img\"],data[\"tar\"]\n        lb_onehot = self.onehot(self.num_class, lb)\n\n        for _ in range(self.num_mix):\n            r = np.random.rand(1)\n            if self.beta <= 0 or r > self.prob:\n                continue\n\n            # generate mixed sample\n            lam = np.random.beta(self.beta, self.beta)\n            rand_index = random.choice(range(len(self)))\n\n            data=self.dataset[rand_index]\n            img2, lb2 = data[\"img\"],data[\"tar\"]\n            lb2_onehot = self.onehot(self.num_class, lb2)\n\n            bbx1, bby1, bbx2, bby2 = self.rand_bbox(img.size(), lam)\n            img[:, bbx1:bbx2, bby1:bby2] = img2[:, bbx1:bbx2, bby1:bby2]\n            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n            lb_onehot = lb_onehot * lam + lb2_onehot * (1. - lam)\n\n        return {\n            \"img\":torch.tensor(img, dtype=torch.float),\n            \"tar\":torch.tensor(lb_onehot, dtype=torch.long)\n        }\n\n    def __len__(self):\n        return len(self.dataset)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EfficientNet\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import EfficientNet\nclass EffiNet(nn.Module):\n    def __init__(self):\n        super(EffiNet, self).__init__()\n        self.base_model = EfficientNet.from_pretrained(\"efficientnet-b4\")\n        num_ftrs = self.base_model._fc.in_features\n        self.base_model._fc = nn.Linear(num_ftrs,4, bias = True)\n        \n    def forward(self, image):\n        out = self.base_model(image)\n        return out\n# Resnet50\nimport torchvision\nclass Resnet50(nn.Module):\n    def __init__(self,model_no):\n        super(Resnet50, self).__init__()\n        self.base_model = torchvision.models.resnext50_32x4d(pretrained=True)\n        num_ftrs = self.base_model.fc.in_features\n        self.base_model.fc = nn.Linear(num_ftrs,4, bias = True)\n        \n    def forward(self, image):\n        out = self.base_model(image)\n        return out    \nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import EfficientNet\nclass EffiNet7(nn.Module):\n    def __init__(self):\n        super(EffiNet7, self).__init__()\n        self.base_model = EfficientNet.from_pretrained(\"efficientnet-b7\")\n        num_ftrs = self.base_model._fc.in_features\n        self.base_model._fc = nn.Linear(num_ftrs,4, bias = True)\n        \n    def forward(self, image):\n        out = self.base_model(image)\n        return out \n# densenet\nimport torchvision\nclass Densenet(nn.Module):\n    def __init__(self,model_no):\n        super(Densenet, self).__init__()\n        self.base_model = torchvision.models.densenet161(pretrained=True)\n        num_ftrs = self.base_model.classifier.in_features\n        self.base_model.classifier = nn.Linear(num_ftrs,4, bias = True)\n        \n    def forward(self, image):\n        out = self.base_model(image)\n        return out    ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensor, ToTensorV2\nSIZE=224\nimport random\n\nclass Utils:\n    def __init__():\n        pass\n    def get_aug(mode=\"train\"):\n        if mode==\"Nor\":\n            aug=A.Compose([\n                ToTensor(),\n            ])\n        elif mode ==\"train\":\n            aug=A.Compose([\n                #A.RandomResizedCrop(height=SIZE, width=SIZE, p=1.0),\n                A.Flip(),\n                A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n\n                # Pixels\n                A.OneOf([\n                    A.IAAEmboss(p=1.0),\n                    A.IAASharpen(p=1.0),\n                    A.Blur(p=1.0),\n                ], p=0.5),\n\n                # Affine\n                A.OneOf([\n                    A.ElasticTransform(p=1.0),\n                    A.IAAPiecewiseAffine(p=1.0)\n                ], p=0.5),\n\n                A.Normalize(p=1.0),\n                ToTensor(),\n            ])\n        else:\n            aug=A.Compose([\n                A.Normalize(p=1.0),\n                ToTensor(),\n            ])\n\n        return aug ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## My Image cumix test\n# import matplotlib.pyplot as plt\n\n# train_df=train[train.kfold!=0].reset_index(drop=True)\n# imgs=train_df.image_id.values.tolist()\n# path=\"../input/plant-images-224-224/\"\n# train_imgs=[path+file+\".png\" for file in imgs]\n# train_aug=Utils.get_aug(\"Nor\")\n# train_tar=train_df.category.values\n# train_dataset=ClassificationLoader(\n#     image_paths=train_imgs,targets=train_tar,resize=None,augmentations=train_aug\n# )\n# CutMix_train_dataloader = CutMix(train_dataset, \n#                           num_class=4, \n#                           beta=1.0, \n#                           prob=0.999, \n#                           num_mix=1)\n# train_loader=torch.utils.data.DataLoader(\n#     CutMix_train_dataloader,batch_size=128,num_workers=4,shuffle=True)\n\n# cnt=0\n# for img,tar in train_loader:\n#     for i in range(128):\n#         img2=img[i].permute(1,2,0)\n#         tar2=tar[i].numpy()\n#         #print(tar2)        \n#         plt.imshow(np.uint(img2*256))\n#         plt.figure()\n#         cnt+=1\n#     if cnt>10:\n#         break","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clcarwin / focal_loss_pytorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int,long)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim()>2:\n            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n        target = target.view(-1,1)\n\n        logpt = F.log_softmax(input)\n        logpt = logpt.gather(1,target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type()!=input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0,target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n        if self.size_average: return loss.mean()\n        else: return loss.sum()","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# My Focal Loss\nclass FocalLoss2(nn.Module):\n    def __init__(self, gamma=0, eps=1e-7):\n        super(FocalLoss2, self).__init__()\n        self.gamma = gamma\n        self.eps = eps\n    def fl_onehot(self,index,classes,tar):\n        y_onehot = torch.FloatTensor(index, classes).to(\"cuda\")\n        y_onehot.zero_()\n        y_onehot.scatter_(1, tar, 1)\n        return (y_onehot)        \n    def forward(self, inputs, targets):\n        y = self.fl_onehot(inputs.size()[0],inputs.size()[1],targets.view(-1,1))\n        logit = F.softmax(inputs, dim=-1)\n        logit = logit.clamp(self.eps, 1. - self.eps)\n\n        loss = -1 * y * torch.log(logit) # cross entropy\n        loss = loss * (1 - logit) ** self.gamma # focal loss\n\n        return loss.mean()  ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# My Focal Loss\nclass FocalLoss3(nn.Module):# for cutmix\n    def __init__(self, gamma=0, eps=1e-7):\n        super(FocalLoss3, self).__init__()\n        self.gamma = gamma\n        self.eps = eps\n    def fl_onehot(self,index,classes,tar):\n        y_onehot = torch.FloatTensor(index, classes).to(\"cuda\")\n        y_onehot.zero_()\n        y_onehot.scatter_(1, tar, 1)\n        return (y_onehot)        \n    def forward(self, inputs, targets):\n        logit = F.softmax(inputs, dim=-1)\n        logit = logit.clamp(self.eps, 1. - self.eps)\n\n        loss = -1 * targets * torch.log(logit) # cross entropy\n        loss = loss * (1 - logit) ** self.gamma # focal loss\n\n        return loss.mean()  ","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nclass DenseCrossEntropy(nn.Module):\n\n    def __init__(self):\n        super(DenseCrossEntropy, self).__init__()\n        \n        \n    def forward(self, logits, labels):\n        logits = logits.float()\n        labels = labels.float()\n        \n        logprobs = F.log_softmax(logits, dim=-1)\n        \n        loss = -labels * logprobs\n        loss = loss.sum(-1)\n\n        return loss.mean()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import accuracy_score\n\n# labels_for_acc = []\n# out_for_acc = []\n# for i in range(5):\n#     d1=np.random.randint(0,10,(10,4))\n#     d2=np.random.randint(0,10,(10,4))\n#     if len(labels_for_acc)==0:\n#         labels_for_acc=d1\n#         out_for_acc=d2\n#     else:\n#         labels_for_acc=np.vstack((labels_for_acc, d1))\n#         out_for_acc=np.vstack((out_for_acc, d2))\n        \n# print(\"data concat\",labels_for_acc)   \n# print(labels_for_acc.shape)\n# print(out_for_acc.shape)\n# print(accuracy_score(labels_for_acc.argmax(1), out_for_acc.argmax(1)))\n# (labels_for_acc.argmax(1)==out_for_acc.argmax(1)).sum()/labels_for_acc.shape[0]","execution_count":14,"outputs":[{"output_type":"stream","text":"data concat [[3 1 0 2]\n [8 2 6 6]\n [1 5 0 9]\n [6 5 5 6]\n [0 7 2 5]\n [5 8 8 7]\n [8 1 1 4]\n [3 5 1 9]\n [8 5 6 6]\n [4 7 3 1]\n [2 3 2 8]\n [4 6 8 5]\n [1 3 7 0]\n [8 7 6 7]\n [1 0 1 3]\n [5 3 9 9]\n [6 7 9 2]\n [3 8 8 8]\n [9 5 8 5]\n [1 1 3 1]\n [4 9 0 9]\n [9 7 7 9]\n [4 6 4 3]\n [1 9 4 6]\n [6 7 8 0]\n [7 2 9 1]\n [4 5 1 6]\n [3 3 5 7]\n [5 1 9 1]\n [0 0 8 1]\n [0 3 8 5]\n [5 3 4 2]\n [4 5 8 7]\n [6 2 2 7]\n [8 7 2 4]\n [1 5 3 6]\n [0 4 1 2]\n [0 8 3 2]\n [6 1 5 8]\n [3 8 2 5]\n [9 8 2 9]\n [4 7 0 1]\n [9 3 0 6]\n [3 5 7 1]\n [7 6 1 5]\n [4 3 7 4]\n [1 0 0 6]\n [2 0 9 4]\n [2 1 4 4]\n [7 8 7 7]]\n(50, 4)\n(50, 4)\n0.28\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"0.28"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Engine\nfrom sklearn.metrics import accuracy_score\nclass Engine:\n    def __init__(self,model,optimizer,device):\n        self.model=model\n        self.optimizer=optimizer\n        self.device=device\n    \n    def loss_fn(self,targets,outputs):\n        #return DenseCrossEntropy()(outputs,targets)\n        #return nn.CrossEntropyLoss()(outputs,targets)\n        #return FocalLoss2()(outputs,targets)\n        return FocalLoss3()(outputs,targets)\n    \n    def train(self,data_loader):\n        preds_for_acc = []\n        labels_for_acc = []\n        self.model.train()\n        final_loss=0\n        for data in data_loader:\n            self.optimizer.zero_grad()\n            inputs=data[\"img\"].to(self.device)\n            targets=data[\"tar\"].to(self.device)\n            outputs=self.model(inputs)\n            loss=self.loss_fn(targets,outputs)\n            loss.backward()\n            self.optimizer.step()\n            final_loss += loss.item()\n            ## Acc Check\n            #labels_for_acc = np.concatenate((labels_for_acc, targets.cpu().numpy()), 0)\n            #preds_for_acc = np.concatenate((preds_for_acc, np.argmax(outputs.cpu().detach().numpy(), 1)), 0)\n            if len(labels_for_acc)==0:\n                labels_for_acc = targets.cpu().numpy()\n                preds_for_acc = outputs.cpu().detach().numpy()\n            else:\n                labels_for_acc=np.vstack((labels_for_acc,targets.cpu().numpy()))\n                preds_for_acc=np.vstack((preds_for_acc,outputs.cpu().detach().numpy()))\n        accuracy = np.uint(labels_for_acc.argmax(1)==preds_for_acc.argmax(1)).sum()/labels_for_acc.shape[0]\n        return final_loss/len(data_loader),accuracy\n    \n    def validate(self,data_loader):\n        preds_for_acc = []\n        labels_for_acc = []\n        self.model.eval()\n        final_loss=0\n        for data in data_loader:\n            inputs=data[\"img\"].to(self.device)\n            targets=data[\"tar\"].to(self.device)\n            with torch.no_grad():\n                outputs=self.model(inputs)\n                loss=self.loss_fn(targets,outputs)\n                final_loss += loss.item()\n            ## Acc Check\n            #labels_for_acc = np.concatenate((labels_for_acc, targets.cpu().numpy()), 0)\n            #preds_for_acc = np.concatenate((preds_for_acc, np.argmax(outputs.cpu().detach().numpy(), 1)), 0)\n            if len(labels_for_acc)==0:\n                labels_for_acc = targets.cpu().numpy()\n                preds_for_acc = outputs.cpu().detach().numpy()\n            else:\n                labels_for_acc=np.vstack((labels_for_acc,targets.cpu().numpy()))\n                preds_for_acc=np.vstack((preds_for_acc,outputs.cpu().detach().numpy()))\n        accuracy = np.uint(labels_for_acc.argmax(1)==preds_for_acc.argmax(1)).sum()/labels_for_acc.shape[0]\n        return final_loss/len(data_loader),accuracy\n    \n    def predict(self,data_loader):\n        self.model.eval()\n        final_predictions = []\n        for data in data_loader:\n            inputs=data[\"img\"].to(self.device)\n            predictions = self.model(inputs)\n            predictions = predictions.cpu()\n            final_predictions.append(predictions.detach().numpy())\n        return final_predictions","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_info=dict()\nvalid_info=dict()\ndef ready_train_info(fold):\n    key=f\"Fold[{fold}]_Acc\"\n    train_info[key]=[]\n    key=f\"Fold[{fold}]_loss\"\n    train_info[key]=[]    \n    key=f\"Fold[{fold}]_Acc\"\n    valid_info[key]=[]\n    key=f\"Fold[{fold}]_loss\"\n    valid_info[key]=[]     \n    \ndef add_train_info(fold, train_acc,train_loss,valid_acc,valid_loss):\n    key=f\"Fold[{fold}]_Acc\"\n    train_info[key].append(train_acc)\n    key=f\"Fold[{fold}]_loss\"\n    train_info[key].append(train_loss)\n    key=f\"Fold[{fold}]_Acc\"\n    valid_info[key].append(valid_acc)\n    key=f\"Fold[{fold}]_loss\"\n    valid_info[key].append(valid_loss)  ","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs_train=16\nbs_valid=12\n\nimport datetime\ndef loop_train(fold=0):\n    ready_train_info(fold)\n    train_df=train[train.kfold!=fold].reset_index(drop=True)#[0:32]\n    valid_df=train[train.kfold==fold].reset_index(drop=True)#[0:32]\n\n    imgs=train_df.image_id.values.tolist()\n    path=\"../input/plant-images-224-224/\"\n    train_imgs=[path+file+\".png\" for file in imgs]\n    train_aug=Utils.get_aug(\"train\")\n    #train_tar=train_df[[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"]].values\n    train_tar=train_df.category.values\n    train_dataset=ClassificationLoader(\n        image_paths=train_imgs,targets=train_tar,resize=None,augmentations=train_aug\n    )\n    CutMix_train_dataloader = CutMix(train_dataset, \n                          num_class=4, \n                          beta=1.0, \n                          prob=0.999, \n                          num_mix=1)\n    train_loader=torch.utils.data.DataLoader(\n        CutMix_train_dataloader,batch_size=bs_train,num_workers=4,shuffle=True\n    )\n    \n    imgs=valid_df.image_id.values.tolist()\n    path=\"../input/plant-images-224-224/\"\n    valid_imgs=[path+file+\".png\" for file in imgs]\n    valid_aug=Utils.get_aug(\"valid\")\n    #valid_tar=valid_df[[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"]].values\n    valid_tar=valid_df.category.values\n    valid_dataset=ClassificationLoader(\n        image_paths=valid_imgs,targets=valid_tar,resize=None,augmentations=valid_aug\n    )\n    CutMix_valid_dataloader = CutMix(valid_dataset, \n                          num_class=4, \n                          beta=1.0, \n                          prob=0, \n                          num_mix=1)\n    valid_loader=torch.utils.data.DataLoader(\n        CutMix_valid_dataloader,batch_size=bs_valid,num_workers=4,shuffle=False\n    )\n    \n    # Model,Optimizer, scheduler, engine\n    model=get_model(model_name)\n    \n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model=model.to(device)\n    optimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\n    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,patience=3,threshold=1e-5,mode=\"min\",verbose=True\n    )\n\n    engine=Engine(model,optimizer,device)\n    best_loss=np.inf\n    early_stopping=7#3\n    early_stopping_cnt=0\n    EPOCH=300\n    for epoch in range(EPOCH):\n        train_loss,train_acc=engine.train(train_loader)\n        valid_loss,valid_acc=engine.validate(valid_loader)\n        scheduler.step(valid_loss)\n        \n        # Add train Info\n        add_train_info(fold,train_acc,train_loss,valid_acc,valid_loss)\n        \n        if valid_loss<best_loss :\n            best_loss=valid_loss\n            torch.save(model.state_dict(),f\"model_fold_{fold}.bin\")\n            tm=datetime.datetime.now().strftime(\"%H:%M:%S\")\n            print(f\"{tm}, fold={fold}, epoch={epoch}, train_loss={train_loss:.6f}, valid_loss={valid_loss:.6f}\")    \n            early_stopping_cnt=0\n        else:\n            early_stopping_cnt+=1\n        if early_stopping_cnt>early_stopping:\n            break\n\n    print(f\"fold={fold}, best val loss={best_loss}\")","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loop_train(fold=0)\nloop_train(fold=1)\nloop_train(fold=2)\nloop_train(fold=3)\nloop_train(fold=4)\n","execution_count":34,"outputs":[{"output_type":"stream","text":"Loaded pretrained weights for efficientnet-b4\n10:18:49, fold=0, epoch=0, train_loss=0.088920, valid_loss=0.215254\n10:20:22, fold=0, epoch=1, train_loss=0.041050, valid_loss=0.092403\n10:21:49, fold=0, epoch=2, train_loss=0.018048, valid_loss=0.081035\n10:23:19, fold=0, epoch=3, train_loss=0.018406, valid_loss=0.072008\n10:24:48, fold=0, epoch=4, train_loss=0.020089, valid_loss=0.069869\n10:26:21, fold=0, epoch=5, train_loss=0.014227, valid_loss=0.065572\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-5ca1f89db5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloop_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloop_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloop_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloop_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloop_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-d76ad970294e>\u001b[0m in \u001b[0;36mloop_train\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mEPOCH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-b2df2c29f8f3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfinal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs_test=12\ndef predict(fold=0,model_no=0):    \n    df=pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n    imgs=df.image_id.values.tolist()\n    path=\"../input/plant-images-224-224/\"\n    test_imgs=[path+file+\".png\" for file in imgs]\n    test_aug=Utils.get_aug(\"test\")\n    test_tar=np.zeros((len(imgs),4))\n    test_dataset=ClassificationLoader(\n        image_paths=test_imgs,targets=test_tar,resize=None,augmentations=test_aug\n    )\n    test_loader=torch.utils.data.DataLoader(\n        test_dataset,batch_size=bs_test,num_workers=0,shuffle=False\n    )\n\n    model=get_model(model_name)\n    model_save_path=f\"./model_fold_{fold}.bin\"\n    model.load_state_dict(torch.load(model_save_path))\n    model=model.to(device)\n\n    engine=Engine(model,None,device)\n    preds=engine.predict(test_loader)\n    preds=np.vstack(preds)\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.special import softmax\n\nd1=predict(fold=0,model_no=4)\nd2=predict(fold=0,model_no=4)\nd3=predict(fold=0,model_no=4)\nd4=predict(fold=0,model_no=4)\nd5=predict(fold=0,model_no=4)\n\np1 = softmax(d1, axis=1)\np2 = softmax(d2, axis=1)\np3 = softmax(d3, axis=1)\np4 = softmax(d4, axis=1)\np5 = softmax(d5, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=(p1+p2+p3+p4+p5)/5\np = softmax(p, axis=1)\nsubmission_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/sample_submission.csv\")\nsubmission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = p\nsubmission_df.to_csv(f'{version_info}_{model_name}_submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold=0\nplt.figure()\nplt.ylim(0,1.5)\n\nkey=f\"Fold[{fold}]_Acc\"\nsns.lineplot(list(range(len(train_info[key]))), train_info[key])\nsns.lineplot(list(range(len(valid_info[key]))), valid_info[key])\nplt.xlabel('Epoch')\nplt.ylabel('Acc')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold=0\nplt.figure()\nplt.ylim(0,15)\n\nkey=f\"Fold[{fold}]_loss\"\nsns.lineplot(list(range(len(train_info[key]))), train_info[key])\nsns.lineplot(list(range(len(valid_info[key]))), valid_info[key])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}