{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:36:40.103136Z",
     "start_time": "2020-06-03T12:36:40.094134Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_rows = 150\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "batch_size=48\n",
    "epochs=300\n",
    "subject='Plant-pathology-2020'\n",
    "main_path=os.path.join(\"E:\\\\kaggle_imgs\",subject)\n",
    "img_path=os.path.join(main_path,\"images\")\n",
    "data_path=os.path.join(main_path,\"Data\")\n",
    "saved_path=os.path.join(main_path,\"saved_models\")\n",
    "paths=[main_path, img_path,saved_path,data_path]\n",
    "for fp in paths:\n",
    "    print(fp)\n",
    "    if not os.path.exists(fp):        \n",
    "        os.mkdir(fp)\n",
    "file_path=os.path.join(saved_path,subject+\"eda_200607_\")\n",
    "file_best=os.path.join(saved_path,subject+\"eda_200607_\")\n",
    "\n",
    "train_img_pkl=os.path.join(data_path,\"train_imgs.npy\")\n",
    "test_img_pkl=os.path.join(data_path,\"test_imgs.npy\")\n",
    "train_info_pkl=os.path.join(data_path,\"df_train_pickle.csv\")\n",
    "\n",
    "num_classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "SAMPLE_LEN = 100\n",
    "IMAGE_PATH =img_path\n",
    "TEST_PATH = data_path+\"/test.csv\"\n",
    "TRAIN_PATH = data_path+\"/train.csv\"\n",
    "SUB_PATH = data_path+\"/sample_submission.csv\"\n",
    "\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_id):\n",
    "    file_path=image_id+\".jpg\"\n",
    "    image=cv2.imread(IMAGE_PATH+\"/\"+file_path)\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "train_images=train_data[\"image_id\"][:SAMPLE_LEN].progress_apply(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.imshow(cv2.resize(train_images[0],(205,136)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution of channel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_values=[np.mean(train_images[idx][:,:,0]) for idx in range(len(train_images))]\n",
    "green_values=[np.mean(train_images[idx][:,:,1]) for idx in range(len(train_images))]\n",
    "blue_values=[np.mean(train_images[idx][:,:,2]) for idx in range(len(train_images))]\n",
    "values=[np.mean(train_images[idx]) for idx in range(len(train_images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_distplot([values], group_labels=[\"Channels\"], colors=[\"purple\"])\n",
    "fig.update_layout(showlegend=False, template=\"simple_white\")\n",
    "fig.update_layout(title_text=\"Distribution of channel values\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_train[\"CAT\"]=df_train[['healthy', 'multiple_diseases', 'rust', 'scab']].values.argmax(axis=1)\n",
    "all_image=[]\n",
    "for i, image_name  in enumerate(df_train.image_id):\n",
    "    if i==100:\n",
    "        break\n",
    "    all_image.append(load_image(image_name))\n",
    "all_image=np.stack(all_image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values=all_image.mean(axis=(1,2,3)).astype(np.uint8)\n",
    "new_color_val=all_image.mean(axis=(1,2)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(new_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(15,5))\n",
    "sns.distplot(new_color_val[:,0],bins=50,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(15,5))\n",
    "sns.distplot(new_color_val[:,1],bins=50,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(15,5))\n",
    "sns.distplot(new_color_val[:,2],bins=50,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box1=pd.DataFrame({\"val\":new_color_val[:,0]})\n",
    "df_box2=pd.DataFrame({\"val\":new_color_val[:,1]})\n",
    "df_box3=pd.DataFrame({\"val\":new_color_val[:,2]})\n",
    "df_box1[\"CAT\"]=\"red\"\n",
    "df_box2[\"CAT\"]=\"green\"\n",
    "df_box3[\"CAT\"]=\"blue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box=pd.concat([df_box1,df_box2]).reset_index()\n",
    "df_box=pd.concat([df_box,df_box3]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"CAT\",y=\"val\",data=df_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_distplot([red_values, green_values, blue_values],\n",
    "                         group_labels=[\"R\", \"G\", \"B\"],\n",
    "                         colors=[\"red\", \"green\", \"blue\"])\n",
    "fig.update_layout(title_text=\"Distribution of red channel values\", template=\"simple_white\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig.data[1].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[1].marker.line.width = 0.5\n",
    "fig.data[2].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[2].marker.line.width = 0.5\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize sample leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_leaves(imgs,title=None):\n",
    "    if title:\n",
    "        print(title)\n",
    "    cnt=imgs.shape[0]-1\n",
    "    row=int(cnt/3) +1\n",
    "    col=3\n",
    "    f,ax=plt.subplots(row,col,figsize=(20,5*row))\n",
    "    for idx in range(cnt+1):\n",
    "        r=int(idx/3)\n",
    "        c=idx%3\n",
    "        ax[r][c].imshow(imgs[idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_healthy=df_train[df_train.healthy==1]\n",
    "imgs_healthy=[]\n",
    "for i,(name)  in enumerate(df_healthy.image_id):\n",
    "    if i==9:\n",
    "        break\n",
    "    imgs_healthy.append(load_image(name))\n",
    "imgs_healthy=np.stack(imgs_healthy,axis=0)   \n",
    "visualize_leaves(imgs_healthy,\"Healthy leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_healthy=df_train[df_train.CAT==3]\n",
    "imgs_healthy=[]\n",
    "for i,(name)  in enumerate(df_healthy.image_id):\n",
    "    if i==9:\n",
    "        break\n",
    "    imgs_healthy.append(load_image(name))\n",
    "imgs_healthy=np.stack(imgs_healthy,axis=0)   \n",
    "visualize_leaves(imgs_healthy,\"scab leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_healthy=df_train[df_train.CAT==2]\n",
    "imgs_healthy=[]\n",
    "for i,(name)  in enumerate(df_healthy.image_id):\n",
    "    if i==9:\n",
    "        break\n",
    "    imgs_healthy.append(load_image(name))\n",
    "imgs_healthy=np.stack(imgs_healthy,axis=0)   \n",
    "visualize_leaves(imgs_healthy,\"rust leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_healthy=df_train[df_train.CAT==1]\n",
    "imgs_healthy=[]\n",
    "for i,(name)  in enumerate(df_healthy.image_id):\n",
    "    if i==9:\n",
    "        break\n",
    "    imgs_healthy.append(load_image(name))\n",
    "imgs_healthy=np.stack(imgs_healthy,axis=0)   \n",
    "visualize_leaves(imgs_healthy,\"multiple diseases leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"SUM\"]=df_train[['healthy', 'multiple_diseases', 'rust', 'scab']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "df_train.CAT=df_train.CAT.apply(lambda x : category[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count plt for category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_train.CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"IsHealthy\"]=df_train.CAT==\"healthy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(df_train.IsHealthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_and_cut(img):\n",
    "    emb_img = img.copy()\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    edge_coors = []\n",
    "    for i in range(edges.shape[0]):\n",
    "        for j in range(edges.shape[1]):\n",
    "            if edges[i][j] != 0:\n",
    "                edge_coors.append((i, j))\n",
    "    \n",
    "    row_min = edge_coors[np.argsort([coor[0] for coor in edge_coors])[0]][0]\n",
    "    row_max = edge_coors[np.argsort([coor[0] for coor in edge_coors])[-1]][0]\n",
    "    col_min = edge_coors[np.argsort([coor[1] for coor in edge_coors])[0]][1]\n",
    "    col_max = edge_coors[np.argsort([coor[1] for coor in edge_coors])[-1]][1]\n",
    "    new_img = img[row_min:row_max, col_min:col_max]\n",
    "    \n",
    "    emb_img[row_min-10:row_min+10, col_min:col_max] = [255, 0, 0]\n",
    "    emb_img[row_max-10:row_max+10, col_min:col_max] = [255, 0, 0]\n",
    "    emb_img[row_min:row_max, col_min-10:col_min+10] = [255, 0, 0]\n",
    "    emb_img[row_min:row_max, col_max-10:col_max+10] = [255, 0, 0]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].set_title('Original Image', fontsize=24)\n",
    "    ax[1].imshow(edges, cmap='gray')\n",
    "    ax[1].set_title('Canny Edges', fontsize=24)\n",
    "    ax[2].imshow(emb_img, cmap='gray')\n",
    "    ax[2].set_title('Bounding Box', fontsize=24)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_and_cut(train_images[3])\n",
    "edge_and_cut(train_images[4])\n",
    "edge_and_cut(train_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation  - Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(img):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('Original Image', fontsize=24)\n",
    "    ax[1].imshow(cv2.flip(img, 0))\n",
    "    ax[1].set_title('Vertical Flip', fontsize=24)\n",
    "    ax[2].imshow(cv2.flip(img, 1))\n",
    "    ax[2].set_title('Horizontal Flip', fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert(all_image[3])\n",
    "invert(all_image[4])\n",
    "invert(all_image[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(img):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 20))\n",
    "    kernel = np.ones((7, 7), np.float32)/25\n",
    "    conv = cv2.filter2D(img, -1, kernel)\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('Original Image', fontsize=24)\n",
    "    ax[1].imshow(conv)\n",
    "    ax[1].set_title('Convolved Image', fontsize=24)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(train_images[3])\n",
    "conv(train_images[4])\n",
    "conv(train_images[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(img):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 20))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('Original Image', fontsize=24)\n",
    "    ax[1].imshow(cv2.blur(img, (100, 100)))\n",
    "    ax[1].set_title('Blurred Image', fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur(train_images[3])\n",
    "blur(train_images[4])\n",
    "blur(train_images[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:17.629508Z",
     "start_time": "2020-06-03T12:32:16.851265Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:17.969417Z",
     "start_time": "2020-06-03T12:32:17.629508Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "vis=visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define value tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:17.974420Z",
     "start_time": "2020-06-03T12:32:17.971417Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_tracker(value_plot, value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=value,\n",
    "             win = value_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.011425Z",
     "start_time": "2020-06-03T12:32:17.975418Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_train_info():\n",
    "    fp=train_info_pkl\n",
    "    if False and os.path.exists(fp):\n",
    "        try:\n",
    "            print('loading train data from csv', flush=True)\n",
    "            df_train=pd.read_csv(fp)\n",
    "            print('complete!', flush=True)\n",
    "        except EOFError:\n",
    "            print('EOFError raised.', flush=True)\n",
    "        \n",
    "    else:\n",
    "        df_train=pd.read_csv(data_path+\"/train.csv\")\n",
    "        df_train[\"CAT\"]=df_train[['healthy', 'multiple_diseases', 'rust','scab']].values.argmax(axis=1)\n",
    "        df_train[\"id\"]=df_train[\"image_id\"].apply(lambda x : int(x.split(\"_\")[1]))        \n",
    "        X=df_train['id'].values\n",
    "        y=df_train['CAT'].values\n",
    "        skf=StratifiedKFold(n_splits=5,random_state=22)        \n",
    "        df_train[\"fold\"]=-1\n",
    "        sum=0\n",
    "        for i, (trn_idx,vld_idx) in enumerate(skf.split(X,y)):\n",
    "            df_train.loc[vld_idx,\"fold\"]=i\n",
    "        df_train.to_csv(train_info_pkl,index=False)\n",
    "        \n",
    "    return df_train\n",
    "\n",
    "df_train=read_train_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.019427Z",
     "start_time": "2020-06-03T12:32:18.012426Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "#    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize((img_rows,img_cols),interpolation=Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize((img_rows,img_cols),interpolation=Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.5, 1/0.5, 1/0.5 ]),\n",
    "                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:30:01.941063Z",
     "start_time": "2020-06-02T12:30:01.936064Z"
    }
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, Rotate, Cutout, HorizontalFlip, Normalize\n",
    ")\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "transform_train_al= Compose([\n",
    "    Rotate(20),\n",
    "    ToTensor()\n",
    "])\n",
    "transform_valid_al=Compose([\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:07:33.102842Z",
     "start_time": "2020-06-02T12:07:33.100850Z"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.026429Z",
     "start_time": "2020-06-03T12:32:18.020427Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, tr=None):\n",
    "        self.df = df\n",
    "        self.tr=tr\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        name=self.df.iloc[idx].image_id\n",
    "        image_src=img_path+\"/\"+name+\".jpg\"\n",
    "        image = Image.open(image_src)\n",
    "        labels = self.df.iloc[idx].CAT\n",
    "\n",
    "        if self.tr is not None:\n",
    "            image=self.tr(image)\n",
    "        \n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:02:24.344826Z",
     "start_time": "2020-06-02T12:02:24.339825Z"
    }
   },
   "source": [
    "## transforms and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.057437Z",
     "start_time": "2020-06-03T12:32:18.050434Z"
    }
   },
   "outputs": [],
   "source": [
    "sel=1\n",
    "trn_fold=[i for i in range(5) if i not in [sel]]\n",
    "val_fold=[i for i in range(5) if i in [sel]]\n",
    "trn_idx=df_train[df_train.fold.isin(trn_fold)].index\n",
    "val_idx=df_train[df_train.fold.isin(val_fold)].index\n",
    "print(trn_idx.shape,val_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.065438Z",
     "start_time": "2020-06-03T12:32:18.058437Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = PlantDataset(df=df_train.loc[trn_idx],\n",
    "                       tr=transform_train)\n",
    "validset =PlantDataset(df=df_train.loc[val_idx],\n",
    "                      tr=transform_valid)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(validset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,lab in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.069439Z",
     "start_time": "2020-06-03T12:32:18.066438Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.075440Z",
     "start_time": "2020-06-03T12:32:18.070439Z"
    }
   },
   "outputs": [],
   "source": [
    "# conv1x1=resnet.conv1x1\n",
    "# Bottleneck = resnet.Bottleneck\n",
    "# BasicBlock= resnet.BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:18.093444Z",
     "start_time": "2020-06-03T12:32:18.076439Z"
    }
   },
   "outputs": [],
   "source": [
    "# class ResNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "#         super(ResNet, self).__init__()\n",
    "#         self.inplanes = 16\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
    "#                                bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "#         self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n",
    "#         self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n",
    "        \n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(128 * block.expansion, num_classes)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#         # Zero-initialize the last BN in each residual branch,\n",
    "#         # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "#         # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "#         if zero_init_residual:\n",
    "#             for m in self.modules():\n",
    "#                 if isinstance(m, Bottleneck):\n",
    "#                     nn.init.constant_(m.bn3.weight, 0)\n",
    "#                 elif isinstance(m, BasicBlock):\n",
    "#                     nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "#     def _make_layer(self, block, planes, blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "#             downsample = nn.Sequential(\n",
    "#                 conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "#                 nn.BatchNorm2d(planes * block.expansion),\n",
    "#             )\n",
    "\n",
    "#         layers = []\n",
    "#         layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "#         self.inplanes = planes * block.expansion\n",
    "#         for _ in range(1, blocks):\n",
    "#             layers.append(block(self.inplanes, planes))\n",
    "\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #[-1,3,32,32]\n",
    "#         x = self.conv1(x)\n",
    "#         #x.shape =[1, 16, 32,32]\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         #x = self.maxpool(x)\n",
    "\n",
    "#         x = self.layer1(x)\n",
    "#         #x.shape =[1, 128, 32,32]\n",
    "#         x = self.layer2(x)\n",
    "#         #x.shape =[1, 256, 32,32]\n",
    "#         x = self.layer3(x)\n",
    "#         #x.shape =[1, 512, 16,16]\n",
    "#         x = self.layer4(x)\n",
    "#         #x.shape =[1, 1024, 8,8]\n",
    "        \n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models  as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:19.444325Z",
     "start_time": "2020-06-03T12:32:18.094444Z"
    }
   },
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "num_ftrs=resnet34.fc.in_features\n",
    "resnet34.fc=nn.Linear(num_ftrs,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34=resnet34.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:20.986755Z",
     "start_time": "2020-06-03T12:32:19.451496Z"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.Tensor(1,3,img_rows,img_cols).to(device)\n",
    "out = resnet34(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:20.991754Z",
     "start_time": "2020-06-03T12:32:20.987754Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss().to(device)\n",
    "optimizer=torch.optim.SGD(resnet34.parameters(),lr=1e-2,momentum=0.9,weight_decay=5e-4)\n",
    "lr_sched=optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:21.007757Z",
     "start_time": "2020-06-03T12:32:20.992755Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),\n",
    "                    opts=dict(title='loss_tracker', \n",
    "                              legend=['loss'], \n",
    "                              showlegend=True))\n",
    "acc_plt = vis.line(Y=torch.Tensor(1).zero_(),\n",
    "                   opts=dict(title='Accuracy', \n",
    "                             legend=['Acc'],\n",
    "                             showlegend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define acc check func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:21.015760Z",
     "start_time": "2020-06-03T12:32:21.009758Z"
    }
   },
   "outputs": [],
   "source": [
    "best_acc=0\n",
    "def acc_check(net, test_set, epoch, save=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    global best_acc\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    acc = (100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % acc)\n",
    "    if save and best_acc<acc:\n",
    "        best_acc=acc\n",
    "        torch.save(net.state_dict(), file_path+\"_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T13:08:46.110268Z",
     "start_time": "2020-06-03T12:38:43.415679Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(len(train_loader))\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    lr_sched.step()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet34(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(train_loader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Check Accuracy\n",
    "    acc = acc_check(resnet34, valid_loader, epoch, save=1)\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T13:09:17.294174Z",
     "start_time": "2020-06-03T13:09:17.278550Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:31.468763Z",
     "start_time": "2020-06-03T12:32:16.001Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.current_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:31.469763Z",
     "start_time": "2020-06-03T12:32:16.002Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T12:32:31.470764Z",
     "start_time": "2020-06-03T12:32:16.004Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
