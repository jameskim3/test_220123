{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "batch_size=80\n",
    "epochs=300\n",
    "cache_path = 'e:/kaggle_imgs/StateFarm'\n",
    "img_path = os.path.join(cache_path,\"Data\",\"imgs\")\n",
    "saved_path=os.path.join(cache_path,\"saved_models\")\n",
    "file_path=os.path.join(cache_path,\"state_vgg16_200514.hdf5\")\n",
    "\n",
    "import shutil\n",
    "paths=[cache_path,img_path,saved_path]\n",
    "for mypath in paths:\n",
    "    if not os.path.exists(mypath):\n",
    "        os.mkdir(mypath)\n",
    "        \n",
    "train_pickle=cache_path+\"/train_data_np.npz\"\n",
    "test_pickle=cache_path+\"/test_data_np.npz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "from PIL import Image as IM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout,Input, Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, img_rows, img_cols, color_type):\n",
    "    color_mode = \"rgb\" if color_type==3 else \"grayscale\"\n",
    "    grayscale = False if color_type==3 else True\n",
    "    img = image.load_img(path, grayscale=grayscale, color_mode=color_mode, \n",
    "                         target_size=(img_rows, img_cols), interpolation=\"nearest\")\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "    \n",
    "\n",
    "def load_train(img_rows, img_cols, color_type, paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        start = time()\n",
    "        files = glob(paths[i])\n",
    "        for j,file in enumerate(files):\n",
    "            images.append(get_image(file, img_rows, img_cols, color_type))\n",
    "            labels.append(i)\n",
    "        print('directory {} loaded in {:.2f} seconds, count:{}'.format(paths[i], time() - start, len(files)))\n",
    "    return images, labels\n",
    "\n",
    "def normalized_train(img_rows, img_cols, color_type,image_path):\n",
    "    path=[]\n",
    "    for i in range(10):\n",
    "        path.append('{}/train/c{}/*.jpg'.format(img_path,i))\n",
    "    images, labels = load_train(img_rows, img_cols, color_type,path)\n",
    "    labels = np_utils.to_categorical(labels, 10)\n",
    "    return images,labels\n",
    "\n",
    "def load_test(img_rows, img_cols, color_type, path):\n",
    "    images = []\n",
    "    files = glob(path)\n",
    "    print(\"test images count :\",len(files))\n",
    "    img_trace_cnt = len(files)//10\n",
    "    for i,file in enumerate(files):\n",
    "        images.append(get_image(file, img_rows, img_cols, color_type))\n",
    "        if(i%img_trace_cnt==0):\n",
    "            print(\"loading count is :\",i)\n",
    "    return images\n",
    "\n",
    "def normalized_test(img_rows, img_cols, color_type,path):\n",
    "    path='{}/test/*.jpg'.format(path)\n",
    "    images = load_test(img_rows, img_cols, color_type, path)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data from pickle\n",
      "complete!\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "fp=train_pickle\n",
    "if os.path.exists(fp):\n",
    "    try:\n",
    "        print('loading train data from pickle', flush=True)\n",
    "        container=np.load(fp)\n",
    "        train_images=container[\"img1\"]\n",
    "        valid_images=container[\"img2\"]\n",
    "        train_labels=container[\"lab1\"]\n",
    "        valid_labels=container[\"lab2\"]\n",
    "        print('complete!', flush=True)\n",
    "    except EOFError:\n",
    "        print('EOFError raised.', flush=True)\n",
    "        print('loading train data...', flush=True)\n",
    "        os.system('rm -f train_data.pickle')\n",
    "else:\n",
    "    print('loading train data...', flush=True)\n",
    "    trains,labels=normalized_train(img_rows, img_cols, color_type,img_path)\n",
    "    train_images, valid_images, train_labels, valid_labels = train_test_split(trains, labels, test_size=0.2)\n",
    "    train_images = np.array(train_images, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "    valid_images = np.array(valid_images, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "    print('train load complete!', flush=True)\n",
    "    print('pickling train data...', flush=True)\n",
    "    start=time()\n",
    "    np.savez(fp, img1=train_images, img2=valid_images, lab1=train_labels, lab2=valid_labels)\n",
    "    print(\"np savez complete, {}\".format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data from pickle\n",
      "complete!, 29.561459064483643\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "fp=test_pickle\n",
    "if os.path.exists(fp):\n",
    "    try:\n",
    "        print('loading test data from pickle', flush=True)\n",
    "        start=time()\n",
    "        container=np.load(fp)\n",
    "        test=container[\"img1\"]\n",
    "        print('complete!, {}'.format(time()-start), flush=True)\n",
    "    except EOFError:\n",
    "        print('EOFError raised.', flush=True)\n",
    "        print('loading test data...', flush=True)\n",
    "        os.system('rm -f test_data.pickle')\n",
    "else:\n",
    "    print('loading test data...', flush=True)\n",
    "    test=normalized_test(img_rows, img_cols, color_type, img_path)\n",
    "    test = np.array(test, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "    print('test load complete!', flush=True)\n",
    "    print('np test data saving...', flush=True)\n",
    "    start=time()\n",
    "    np.savez(fp,img1=test)\n",
    "    print('np test data complete...,{}'.format(time()-start), flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.\n",
    "valid_images=valid_images/255.\n",
    "#test=test/255.\n",
    "#plt.imshow(train_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats:\n",
      "17939 train images\n",
      "4485 validation images\n",
      "0 test images\n",
      "train_images.shape = (17939, 224, 224, 3)\n",
      "train_labels.shape = (17939, 10)\n",
      "valid_images.shape = (4485, 224, 224, 3)\n",
      "valid_labels.shape = (4485, 10)\n"
     ]
    }
   ],
   "source": [
    "3745\n",
    "# stats\n",
    "train_size = len(train_images)\n",
    "valid_size = len(valid_images)\n",
    "test_size = len(glob('data/imgs/test/*.jpg'))\n",
    "print('stats:', flush=True)\n",
    "print('{} train images'.format(train_size), flush=True)\n",
    "print('{} validation images'.format(valid_size), flush=True)\n",
    "print('{} test images'.format(test_size), flush=True)\n",
    "print('train_images.shape = {}'.format(train_images.shape), flush=True)\n",
    "print('train_labels.shape = {}'.format(train_labels.shape), flush=True)\n",
    "print('valid_images.shape = {}'.format(valid_images.shape), flush=True)\n",
    "print('valid_labels.shape = {}'.format(valid_labels.shape), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=file_path, \n",
    "                               monitor='val_loss', mode='min',\n",
    "                               verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=7)\n",
    "learning_rate_reduction=ReduceLROnPlateau(monitor=\"val_acc\",\n",
    "                                          patience=3,\n",
    "                                          verbose=1,\n",
    "                                          factor=0.5,\n",
    "                                          min_lr=0.00001)\n",
    "#callbacks = [checkpoint, es,learning_rate_reduction]\n",
    "callbacks = [checkpoint, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 16,321,034\n",
      "Trainable params: 1,606,346\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base=VGG16(weights=\"imagenet\",\\\n",
    "               include_top=False,\\\n",
    "               input_shape=(img_rows,img_cols,color_type))\n",
    "conv_base.trainable=False\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation configuration\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "validation_data = (valid_images,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight complete\n",
      "Epoch 1/300\n",
      "448/448 [==============================] - 136s 303ms/step - loss: 1.8800 - accuracy: 0.2779 - val_loss: 1.7126 - val_accuracy: 0.3358\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.76888 to 1.71256, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 2/300\n",
      "448/448 [==============================] - 136s 304ms/step - loss: 1.8469 - accuracy: 0.2849 - val_loss: 1.6778 - val_accuracy: 0.3376\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.71256 to 1.67776, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 3/300\n",
      "448/448 [==============================] - 135s 302ms/step - loss: 1.8665 - accuracy: 0.2836 - val_loss: 1.6290 - val_accuracy: 0.3550\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.67776 to 1.62904, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 4/300\n",
      "448/448 [==============================] - 135s 301ms/step - loss: 1.8554 - accuracy: 0.2927 - val_loss: 1.5931 - val_accuracy: 0.3795\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.62904 to 1.59312, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 5/300\n",
      "448/448 [==============================] - 134s 300ms/step - loss: 1.8309 - accuracy: 0.2944 - val_loss: 1.5422 - val_accuracy: 0.4067\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59312 to 1.54220, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 6/300\n",
      "448/448 [==============================] - 135s 302ms/step - loss: 1.8185 - accuracy: 0.3147 - val_loss: 1.5038 - val_accuracy: 0.4243\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.54220 to 1.50378, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 7/300\n",
      "448/448 [==============================] - 135s 301ms/step - loss: 1.7877 - accuracy: 0.3178 - val_loss: 1.4788 - val_accuracy: 0.4317\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.50378 to 1.47884, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 8/300\n",
      "448/448 [==============================] - 135s 302ms/step - loss: 1.7723 - accuracy: 0.3237 - val_loss: 1.4656 - val_accuracy: 0.4330\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.47884 to 1.46564, saving model to e:/kaggle_imgs/StateFarm/saved_models/State_200510_MVgg.hdf5\n",
      "Epoch 9/300\n",
      "448/448 [==============================] - 134s 300ms/step - loss: 1.7755 - accuracy: 0.3149 - val_loss: 1.4713 - val_accuracy: 0.4272\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.46564\n",
      "Epoch 10/300\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.7997 - accuracy: 0.3182"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-51be3fa7a794>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     validation_steps = valid_images.shape[0] // batch_size)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    249\u001b[0m                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                             verbose=0)\n\u001b[0m\u001b[0;32m    252\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                          \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m                                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(file_path):\n",
    "    model.load_weights(file_path)\n",
    "    print(\"load weight complete\")\n",
    "history = model.fit_generator(\n",
    "    training_generator,\n",
    "    epochs = epochs, \n",
    "    validation_data = validation_data,\n",
    "    verbose = 1,\n",
    "    steps_per_epoch = train_images.shape[0] // batch_size,\n",
    "    callbacks=callbacks,\n",
    "    validation_steps = valid_images.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.subplots(figsize=(12,8))\n",
    "plt.plot(history.history['accuracy'],\"r\",label=\"train\")\n",
    "plt.plot(history.history['val_accuracy'],\"bo\",label=\"valid\")\n",
    "plt.title('Model accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(12,8))\n",
    "plt.plot(history.history['loss'],label=\"Model\")\n",
    "plt.plot(history.history['val_loss'],\"bo\",label=\"loss\")\n",
    "plt.title('Model loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission=pd.DataFrame({\"ImageId\":pd.Series(range(1,28001)),\"Label\":results.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# now=datetime.now()\n",
    "# submission.to_csv(\"data/{0:02d}{1:02d}{2:02d}{3:02d}_{}.csv\".\\\n",
    "#                   format(now.year,now.month,now.day,now.hour,subject),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(file_path):\n",
    "    model.load_weights(file_path)\n",
    "    print(\"model load complete\")\n",
    "if os.path.exists(test_pickle):\n",
    "    try:\n",
    "        print('loading test data from pickle', flush=True)\n",
    "        with open(test_pickle, 'rb') as f:\n",
    "            (test_data,test_id) = load(f)\n",
    "        print('complete!', flush=True)\n",
    "    except EOFError:\n",
    "        print('EOFError raised.', flush=True)\n",
    "        print('loading test data...', flush=True)\n",
    "test_data = test_data.astype('float32')\n",
    "test_data =test_data/ 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict(test_data, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull_test=[]\n",
    "yfull_test.append(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join(cache, 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_string = 'r_' + str(img_rows) \\\n",
    "                    + '_c_' + str(img_cols) \\\n",
    "                    + '_ep_' + str(epochs)\n",
    "test_res = merge_several_folds_mean(yfull_test, 1)\n",
    "create_submission(test_res, test_id, info_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
