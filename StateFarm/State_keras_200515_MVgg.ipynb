{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "color_type = 3\n",
    "batch_size=80\n",
    "epochs=300\n",
    "cache_path = 'e:/kaggle_imgs/StateFarm'\n",
    "img_path = os.path.join(cache_path,\"Data\",\"imgs\")\n",
    "saved_path=os.path.join(cache_path,\"saved_models\")\n",
    "file_path=os.path.join(cache_path,\"state_vgg16_200515.hdf5\")\n",
    "\n",
    "import shutil\n",
    "paths=[cache_path,img_path,saved_path]\n",
    "for mypath in paths:\n",
    "    if not os.path.exists(mypath):\n",
    "        os.mkdir(mypath)\n",
    "        \n",
    "train_pickle=cache_path+\"/train_data_np_200515.npy\"\n",
    "test_pickle=cache_path+\"/test_data_np_200515.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "from PIL import Image as IM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout,Input, Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, img_rows, img_cols, color_type):\n",
    "    color_mode = \"rgb\" if color_type==3 else \"grayscale\"\n",
    "    grayscale = False if color_type==3 else True\n",
    "    img = image.load_img(path, grayscale=grayscale, color_mode=color_mode, \n",
    "                         target_size=(img_rows, img_cols), interpolation=\"nearest\")\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "    \n",
    "\n",
    "def load_train(img_rows, img_cols, color_type, paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        start = time()\n",
    "        files = glob(paths[i])\n",
    "        for j,file in enumerate(files):\n",
    "            images.append(get_image(file, img_rows, img_cols, color_type))\n",
    "            labels.append(i)\n",
    "        print('directory {} loaded in {:.2f} seconds, count:{}'.format(paths[i], time() - start, len(files)))\n",
    "    return images, labels\n",
    "\n",
    "def normalized_train(img_rows, img_cols, color_type,image_path):\n",
    "    path=[]\n",
    "    for i in range(10):\n",
    "        path.append('{}/train/c{}/*.jpg'.format(img_path,i))\n",
    "    images, labels = load_train(img_rows, img_cols, color_type,path)\n",
    "    labels = np_utils.to_categorical(labels, 10)\n",
    "    return images,labels\n",
    "\n",
    "def load_test(img_rows, img_cols, color_type, path):\n",
    "    images = []\n",
    "    files = glob(path)\n",
    "    print(\"test images count :\",len(files))\n",
    "    img_trace_cnt = len(files)//10\n",
    "    for i,file in enumerate(files):\n",
    "        images.append(get_image(file, img_rows, img_cols, color_type))\n",
    "        if(i%img_trace_cnt==0):\n",
    "            print(\"loading count is :\",i)\n",
    "    return images\n",
    "\n",
    "def normalized_test(img_rows, img_cols, color_type,path):\n",
    "    path='{}/test/*.jpg'.format(path)\n",
    "    images = load_test(img_rows, img_cols, color_type, path)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data from pickle\n",
      "complete!\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "fp=train_pickle\n",
    "if os.path.exists(fp):\n",
    "    try:\n",
    "        print('loading train data from pickle', flush=True)\n",
    "        [train_images, valid_images, train_labels, valid_labels]=np.load(fp,allow_pickle=True)\n",
    "        print('complete!', flush=True)\n",
    "    except EOFError:\n",
    "        print('EOFError raised.', flush=True)\n",
    "        print('loading train data...', flush=True)\n",
    "        os.system('rm -f train_data.pickle')\n",
    "else:\n",
    "    print('loading train data...', flush=True)\n",
    "    trains,labels=normalized_train(img_rows, img_cols, color_type,img_path)\n",
    "    train_images, valid_images, train_labels, valid_labels = train_test_split(trains, labels, test_size=0.2)\n",
    "    train_images = np.array(train_images, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "    valid_images = np.array(valid_images, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "    print('train load complete!', flush=True)\n",
    "    print('pickling train data...', flush=True)\n",
    "    start=time()\n",
    "    np.save(fp, np.array([train_images, valid_images, train_labels, valid_labels]))\n",
    "    print(\"np save complete, {}\".format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data from pickle\n",
      "complete!, 98.65489935874939\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "# fp=test_pickle\n",
    "# if os.path.exists(fp):\n",
    "#     try:\n",
    "#         print('loading test data from pickle', flush=True)\n",
    "#         start=time()\n",
    "#         test=np.load(fp,allow_pickle=True)\n",
    "#         print('complete!, {}'.format(time()-start), flush=True)\n",
    "#     except EOFError:\n",
    "#         print('EOFError raised.', flush=True)\n",
    "#         print('loading test data...', flush=True)\n",
    "#         os.system('rm -f test_data.pickle')\n",
    "# else:\n",
    "#     print('loading test data...', flush=True)\n",
    "#     test=normalized_test(img_rows, img_cols, color_type, img_path)\n",
    "#     test = np.array(test, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "#     print('test load complete!', flush=True)\n",
    "#     print('np test data saving...', flush=True)\n",
    "#     start=time()\n",
    "#     np.save(fp,test)\n",
    "#     print('np test data complete...,{}'.format(time()-start), flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.\n",
    "valid_images=valid_images/255.\n",
    "#test=test/255.\n",
    "#plt.imshow(train_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats:\n",
      "17939 train images\n",
      "4485 validation images\n",
      "0 test images\n",
      "train_images.shape = (17939, 224, 224, 3)\n",
      "train_labels.shape = (17939, 10)\n",
      "valid_images.shape = (4485, 224, 224, 3)\n",
      "valid_labels.shape = (4485, 10)\n"
     ]
    }
   ],
   "source": [
    "3745\n",
    "# stats\n",
    "train_size = len(train_images)\n",
    "valid_size = len(valid_images)\n",
    "test_size = len(glob('data/imgs/test/*.jpg'))\n",
    "print('stats:', flush=True)\n",
    "print('{} train images'.format(train_size), flush=True)\n",
    "print('{} validation images'.format(valid_size), flush=True)\n",
    "print('{} test images'.format(test_size), flush=True)\n",
    "print('train_images.shape = {}'.format(train_images.shape), flush=True)\n",
    "print('train_labels.shape = {}'.format(train_labels.shape), flush=True)\n",
    "print('valid_images.shape = {}'.format(valid_images.shape), flush=True)\n",
    "print('valid_labels.shape = {}'.format(valid_labels.shape), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=file_path, \n",
    "                               monitor='val_loss', mode='min',\n",
    "                               verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=7)\n",
    "learning_rate_reduction=ReduceLROnPlateau(monitor=\"val_acc\",\n",
    "                                          patience=3,\n",
    "                                          verbose=1,\n",
    "                                          factor=0.5,\n",
    "                                          min_lr=0.00001)\n",
    "#callbacks = [checkpoint, es,learning_rate_reduction]\n",
    "callbacks = [checkpoint, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,927,370\n",
      "Trainable params: 3,212,682\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import optimizers\n",
    "\n",
    "def get_model():\n",
    "    conv_base=VGG16(weights=\"imagenet\",\n",
    "                   include_top=False,\n",
    "                   input_shape=(img_rows,img_cols,color_type))\n",
    "    conv_base.trainable=False\n",
    "    model = Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation configuration\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "validation_data = (valid_images,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "224/224 [==============================] - 185s 828ms/step - loss: 1.2183 - accuracy: 0.6451 - val_loss: 0.3557 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35570, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 2/300\n",
      "224/224 [==============================] - 182s 811ms/step - loss: 0.4046 - accuracy: 0.9038 - val_loss: 0.2087 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35570 to 0.20873, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 3/300\n",
      "224/224 [==============================] - 182s 813ms/step - loss: 0.2279 - accuracy: 0.9466 - val_loss: 0.1004 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20873 to 0.10039, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 4/300\n",
      "224/224 [==============================] - 182s 814ms/step - loss: 0.1526 - accuracy: 0.9634 - val_loss: 0.0682 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10039 to 0.06819, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 5/300\n",
      "224/224 [==============================] - 183s 815ms/step - loss: 0.1242 - accuracy: 0.9710 - val_loss: 0.0564 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06819 to 0.05644, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 6/300\n",
      "224/224 [==============================] - 181s 808ms/step - loss: 0.0954 - accuracy: 0.9766 - val_loss: 0.0540 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05644 to 0.05401, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 7/300\n",
      "224/224 [==============================] - 182s 811ms/step - loss: 0.0769 - accuracy: 0.9806 - val_loss: 0.0458 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05401 to 0.04578, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 8/300\n",
      "224/224 [==============================] - 183s 817ms/step - loss: 0.0640 - accuracy: 0.9848 - val_loss: 0.0546 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04578\n",
      "Epoch 9/300\n",
      "224/224 [==============================] - 185s 826ms/step - loss: 0.0610 - accuracy: 0.9844 - val_loss: 0.0246 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04578 to 0.02456, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 10/300\n",
      "224/224 [==============================] - 182s 814ms/step - loss: 0.0505 - accuracy: 0.9873 - val_loss: 0.0265 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02456\n",
      "Epoch 11/300\n",
      "224/224 [==============================] - 181s 808ms/step - loss: 0.0471 - accuracy: 0.9872 - val_loss: 0.0228 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02456 to 0.02283, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 12/300\n",
      "224/224 [==============================] - 180s 802ms/step - loss: 0.0412 - accuracy: 0.9899 - val_loss: 0.0212 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02283 to 0.02115, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 13/300\n",
      "224/224 [==============================] - 181s 807ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.0178 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02115 to 0.01781, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 14/300\n",
      "224/224 [==============================] - 191s 852ms/step - loss: 0.0334 - accuracy: 0.9911 - val_loss: 0.0228 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01781\n",
      "Epoch 15/300\n",
      "224/224 [==============================] - 190s 847ms/step - loss: 0.0289 - accuracy: 0.9929 - val_loss: 0.0158 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01781 to 0.01576, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 16/300\n",
      "224/224 [==============================] - 177s 791ms/step - loss: 0.0273 - accuracy: 0.9925 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01576 to 0.01435, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 17/300\n",
      "224/224 [==============================] - 177s 790ms/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.0190 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01435\n",
      "Epoch 18/300\n",
      "224/224 [==============================] - 177s 792ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0177 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01435\n",
      "Epoch 19/300\n",
      "224/224 [==============================] - 177s 792ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.0264 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01435\n",
      "Epoch 20/300\n",
      "224/224 [==============================] - 177s 790ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01435\n",
      "Epoch 21/300\n",
      "224/224 [==============================] - 173s 774ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0129 - val_accuracy: 0.9971\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01435 to 0.01291, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 22/300\n",
      "224/224 [==============================] - 182s 813ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0165 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01291\n",
      "Epoch 23/300\n",
      "224/224 [==============================] - 179s 800ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0107 - val_accuracy: 0.9967\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01291 to 0.01072, saving model to e:/kaggle_imgs/StateFarm\\state_vgg16_200515.hdf5\n",
      "Epoch 24/300\n",
      "224/224 [==============================] - 181s 807ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01072\n",
      "Epoch 25/300\n",
      "207/224 [==========================>...] - ETA: 11s - loss: 0.0162 - accuracy: 0.9953"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-51be3fa7a794>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     validation_steps = valid_images.shape[0] // batch_size)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(file_path):\n",
    "    model.load_weights(file_path)\n",
    "    print(\"load weight complete\")\n",
    "history = model.fit_generator(\n",
    "    training_generator,\n",
    "    epochs = epochs, \n",
    "    validation_data = validation_data,\n",
    "    verbose = 1,\n",
    "    steps_per_epoch = train_images.shape[0] // batch_size,\n",
    "    callbacks=callbacks,\n",
    "    validation_steps = valid_images.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.subplots(figsize=(12,8))\n",
    "plt.plot(history.history['accuracy'],\"r\",label=\"train\")\n",
    "plt.plot(history.history['val_accuracy'],\"bo\",label=\"valid\")\n",
    "plt.title('Model accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(12,8))\n",
    "plt.plot(history.history['loss'],label=\"Model\")\n",
    "plt.plot(history.history['val_loss'],\"bo\",label=\"loss\")\n",
    "plt.title('Model loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission=pd.DataFrame({\"ImageId\":pd.Series(range(1,28001)),\"Label\":results.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# now=datetime.now()\n",
    "# submission.to_csv(\"data/{0:02d}{1:02d}{2:02d}{3:02d}_{}.csv\".\\\n",
    "#                   format(now.year,now.month,now.day,now.hour,subject),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFGFDG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(file_path):\n",
    "    model.load_weights(file_path)\n",
    "    print(\"model load complete\")\n",
    "if os.path.exists(test_pickle):\n",
    "    try:\n",
    "        print('loading test data from pickle', flush=True)\n",
    "        with open(test_pickle, 'rb') as f:\n",
    "            (test_data,test_id) = load(f)\n",
    "        print('complete!', flush=True)\n",
    "    except EOFError:\n",
    "        print('EOFError raised.', flush=True)\n",
    "        print('loading test data...', flush=True)\n",
    "test_data = test_data.astype('float32')\n",
    "test_data =test_data/ 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict(test_data, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull_test=[]\n",
    "yfull_test.append(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join(cache, 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_string = 'r_' + str(img_rows) \\\n",
    "                    + '_c_' + str(img_cols) \\\n",
    "                    + '_ep_' + str(epochs)\n",
    "test_res = merge_several_folds_mean(yfull_test, 1)\n",
    "create_submission(test_res, test_id, info_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
