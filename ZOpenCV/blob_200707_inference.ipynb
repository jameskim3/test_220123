{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "img_row = 224\n",
    "img_col = 224\n",
    "batch_size=18\n",
    "\n",
    "subject='hiaa2'\n",
    "main_path=os.path.join(\"E:\\\\kaggle_imgs\",subject)\n",
    "img_path=os.path.join(main_path,\"img\")\n",
    "data_path=os.path.join(main_path,\"data\")\n",
    "saved_path=os.path.join(main_path,\"saved_models\")\n",
    "paths=[main_path, img_path,saved_path,data_path]\n",
    "for fp in paths:\n",
    "    print(fp)\n",
    "    if not os.path.exists(fp):        \n",
    "        os.mkdir(fp)\n",
    "file_path=os.path.join(saved_path,\"epoch_12_loss_0.003064.pth\")\n",
    "file_best=os.path.join(saved_path,\"epoch_12_loss_0.003064.pth\")\n",
    "\n",
    "train_img_pkl=os.path.join(data_path,\"train.csv\")\n",
    "test_img_pkl=os.path.join(data_path,\"test_imgs.npy\")\n",
    "train_info_pkl=os.path.join(data_path,\"df_train_pickle.csv\")\n",
    "\n",
    "num_classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_info():\n",
    "    fp=train_img_pkl\n",
    "    if False and os.path.exists(fp):\n",
    "        try:\n",
    "            print('loading train data from csv', flush=True)\n",
    "            df_train=pd.read_csv(fp)\n",
    "            print('complete!', flush=True)\n",
    "        except EOFError:\n",
    "            print('EOFError raised.', flush=True)\n",
    "    else:\n",
    "        files=os.listdir(os.path.join(img_path,\"train\"))\n",
    "        df_train=pd.DataFrame({\"image_name\":files})\n",
    "        df_train=df_train[~df_train.image_name.str.contains('mask')].reset_index(drop=True)\n",
    "        df_train[\"id\"]=df_train[\"image_name\"].apply(lambda x : int(x.split('.')[0]))\n",
    "        df_train[\"mask_name\"]=df_train[\"id\"].apply(lambda x : str(x)+\"_mask.png\")\n",
    "        kf=KFold(n_splits=5,random_state=22)        \n",
    "        df_train[\"fold\"]=-1\n",
    "        X=df_train.id\n",
    "        for i,(train_idx,valid_idx) in enumerate(kf.split(X)):\n",
    "            df_train.loc[valid_idx,\"fold\"]=i\n",
    "        df_train.to_csv(fp,index=False)\n",
    "        \n",
    "    return df_train\n",
    "    \n",
    "df_train=read_train_info()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, Rotate, Cutout, VerticalFlip, Normalize\n",
    ")\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "valid_transforms =  transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "test_transforms  = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "mask_transforms  = transforms.Compose([\n",
    "                                 transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transforms= Compose([\n",
    "# #     Rotate(15),\n",
    "# #     OneOf([\n",
    "# #         IAAAdditiveGaussianNoise(),\n",
    "# #         GaussNoise(),\n",
    "# #     ], p=0.2),\n",
    "# #     OneOf([\n",
    "# #         MotionBlur(p=0.2),\n",
    "# #         MedianBlur(blur_limit=3, p=0.1),\n",
    "# #         Blur(blur_limit=3, p=0.1),\n",
    "# #     ], p=0.2),\n",
    "# #     ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "# #     OneOf([\n",
    "# #         OpticalDistortion(p=0.3),\n",
    "# #         GridDistortion(p=0.1),\n",
    "# #         IAAPiecewiseAffine(p=0.3),\n",
    "# #     ], p=0.2),\n",
    "# #     OneOf([\n",
    "# #         CLAHE(clip_limit=2),\n",
    "# #         IAASharpen(),\n",
    "# #         IAAEmboss(),\n",
    "# #         RandomBrightnessContrast(),\n",
    "# #     ], p=0.3),\n",
    "# #     HueSaturationValue(p=0.3),\n",
    "# #     Normalize(),\n",
    "#     ToTensor()\n",
    "# ])\n",
    "# valid_transforms=Compose([\n",
    "# #     Normalize(),\n",
    "#     ToTensor()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "from PIL import Image\n",
    "img = Image.open(img_path+\"/train/11000.jpg\")\n",
    "img=np.uint8(img)\n",
    "img = train_transforms(img)\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, tr=None,subset=\"train\"):\n",
    "        self.df = df\n",
    "        self.tr=tr\n",
    "        self.subset=subset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name=self.df.iloc[idx].image_name\n",
    "        if self.subset==\"test\":\n",
    "            img = Image.open(img_path+\"/test/\"+image_name)\n",
    "            img=np.uint8(img)\n",
    "            img = self.tr(img)\n",
    "        else:\n",
    "            img = Image.open(img_path+\"/train/\"+image_name)\n",
    "            img=np.uint8(img)\n",
    "            img = self.tr(img)\n",
    "            \n",
    "        mask=np.zeros_like(img)\n",
    "        if self.subset==\"train\":\n",
    "            mask_name=self.df.iloc[idx].mask_name\n",
    "            mask = Image.open(img_path+\"/train/\"+mask_name)\n",
    "            mask =np.uint8(mask)\n",
    "            mask=mask_transforms(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforms and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_by_fold(fold):\n",
    "    sel=fold\n",
    "    trn_fold=[i for i in range(5) if i not in [sel]]\n",
    "    val_fold=[i for i in range(5) if i in [sel]]\n",
    "    trn_idx=df_train[df_train.fold.isin(trn_fold)].index\n",
    "    val_idx=df_train[df_train.fold.isin(val_fold)].index\n",
    "    trainset = PlantDataset(df=df_train.loc[trn_idx],\n",
    "                           tr=train_transforms)\n",
    "    validset =PlantDataset(df=df_train.loc[val_idx],\n",
    "                          tr=valid_transforms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "    valid_loader = torch.utils.data.DataLoader(validset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False, num_workers=0)\n",
    "    return train_loader,valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,valid_loader=get_images_by_fold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,mask in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0].size(),img[0].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    f,ax=plt.subplots(1,2,figsize=(14,5))\n",
    "    ax[0].imshow(img[i].permute(1,2,0))\n",
    "    ax[1].imshow(mask[i].permute(1,2,0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[i].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(n_class=6)\n",
    "model = model.to(device)\n",
    "\n",
    "# check keras-like model summary using torchsummary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            my_loader= train_loader if phase==\"train\" else valid_loader\n",
    "            for inputs, labels in my_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                state = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                }\n",
    "                file_best=saved_path+\"/epoch_%2d_loss_%.6f.pth\"%(epoch, best_loss)\n",
    "                torch.save(state, file_best)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 1\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "#for l in model.base_layers:\n",
    "#    for param in l.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Best\n",
    " if os.path.isfile(file_best):\n",
    "    checkpoint = torch.load(file_best)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Load Complete\",cur_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "model.eval()\n",
    "\n",
    "# get the first batch\n",
    "for i,(inputs,labels) in enumerate(valid_loader):\n",
    "    inputs=inputs.to(device)\n",
    "    labels=labels.to(device)\n",
    "\n",
    "    #predict\n",
    "    pred=model(inputs)\n",
    "    #The loss fuctions include the sigmoid function.\n",
    "    pred=F.sigmoid(pred)\n",
    "    pred=pred.data.cpu().numpy()\n",
    "    print(pred.shape)\n",
    "\n",
    "    inputs=inputs.to(\"cpu\")\n",
    "    labels=labels.to(\"cpu\")\n",
    "    if i==2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    f,ax=plt.subplots(1,3,figsize=(15,7))\n",
    "    ax[0].imshow(inputs[i].permute(1,2,0)*255)\n",
    "    ax[1].imshow(labels[i].permute(1,2,0).squeeze())\n",
    "    img1=np.uint8(pred[i].squeeze()>0.001)\n",
    "    #ax[2].imshow(inputs[i].permute(1,2,0)*255)\n",
    "    ax[2].imshow(img1, cmap=\"jet\",alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir(os.path.join(img_path,\"test\"))\n",
    "df_test=pd.DataFrame({\"image_name\":files})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = PlantDataset(df=df_test,\n",
    "                   tr=test_transforms,subset=\"test\")\n",
    "test_loader = torch.utils.data.DataLoader(testset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,mask in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "model.eval()\n",
    "\n",
    "# get the first batch\n",
    "for i,(inputs,labels) in enumerate(test_loader):\n",
    "    inputs=inputs.to(device)\n",
    "    labels=labels.to(device)\n",
    "\n",
    "    #predict\n",
    "    pred=model(inputs)\n",
    "    #The loss fuctions include the sigmoid function.\n",
    "    pred=F.sigmoid(pred)\n",
    "    pred=pred.data.cpu().numpy()\n",
    "    print(pred.shape)\n",
    "\n",
    "    inputs=inputs.to(\"cpu\")\n",
    "    labels=labels.to(\"cpu\")\n",
    "    if i==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    f,ax=plt.subplots(1,3,figsize=(15,7))\n",
    "    ax[0].imshow(inputs[i].permute(1,2,0))\n",
    "    ax[1].imshow(labels[i].permute(1,2,0).squeeze())\n",
    "    #img1=np.uint8(pred[i].squeeze()>0.001)\n",
    "    #ax[2].imshow(inputs[i].permute(1,2,0)*255)\n",
    "    ax[2].imshow(pred[i].squeeze(), cmap=\"jet\",alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[i].squeeze().min(),pred[i].squeeze().min(),pred[i].squeeze().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
